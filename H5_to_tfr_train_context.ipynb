{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_series = str(1)\n",
    "addr_X_file = 'TSP/Predicted/predicted_TSP_FFT'  + file_series + '.hdf5'\n",
    "addr_y_file = 'TSP/Organized/concatenated/Second_set/Train2_TSP_clean_FFTs'  + file_series + '.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0    186    387 ... 474040 474199 474382]\n"
     ]
    }
   ],
   "source": [
    "a = h5py.File('TSP/Organized/concatenated/Second_set/all_len'  + file_series + '.hdf5','r')\n",
    "all_len = a['all_len'][:]\n",
    "print(all_len)\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_size = int(np.floor(all_len[-1] / 40))\n",
    "index = np.arange(0, all_len[-1], load_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11859"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_tfrecords(X, Y, file_path_prefix, verbose=True):\n",
    "    \"\"\"\n",
    "    Converts a Numpy array (or two Numpy arrays) into a tfrecord file.\n",
    "    For supervised learning, feed training inputs to X and training labels to Y.\n",
    "    For unsupervised learning, only feed training inputs to X, and feed None to Y.\n",
    "    The length of the first dimensions of X and Y should be the number of samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy.ndarray of rank 2\n",
    "        Numpy array for training inputs. Its dtype should be float32, float64, or int64.\n",
    "        If X has a higher rank, it should be rshape before fed to this function.\n",
    "    Y : numpy.ndarray of rank 2 or None\n",
    "        Numpy array for training labels. Its dtype should be float32, float64, or int64.\n",
    "        None if there is no label array.\n",
    "    file_path_prefix : str\n",
    "        The path and name of the resulting tfrecord file to be generated, without '.tfrecords'\n",
    "    verbose : bool\n",
    "        If true, progress is reported.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input type is not float (64 or 32) or int.\n",
    "    \n",
    "    \"\"\"\n",
    "    def _dtype_feature(ndarray):\n",
    "        \"\"\"match appropriate tf.train.Feature class with dtype of ndarray. \"\"\"\n",
    "        assert isinstance(ndarray, np.ndarray)\n",
    "        dtype_ = ndarray.dtype\n",
    "        if dtype_ == np.float64 or dtype_ == np.float32:\n",
    "            return lambda array: tf.train.Feature(float_list=tf.train.FloatList(value=array))\n",
    "        elif dtype_ == np.float64:\n",
    "            return lambda array: tf.train.Feature(int64_list=tf.train.Int64List(value=array))\n",
    "        else:  \n",
    "            raise ValueError(\"The input should be numpy ndarray. \\\n",
    "                               Instaed got {}\".format(ndarray.dtype))\n",
    "            \n",
    "    assert isinstance(X, np.ndarray)\n",
    "    assert len(X.shape) == 2  # If X has a higher rank, \n",
    "                               # it should be rshape before fed to this function.\n",
    "    assert isinstance(Y, np.ndarray) or Y is None\n",
    "    \n",
    "    # load appropriate tf.train.Feature class depending on dtype\n",
    "    dtype_feature_x = _dtype_feature(X)\n",
    "    if Y is not None:\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        assert len(Y.shape) == 2\n",
    "        dtype_feature_y = _dtype_feature(Y)            \n",
    "    \n",
    "    # Generate tfrecord writer\n",
    "    result_tf_file = file_path_prefix + '.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(result_tf_file)\n",
    "    if verbose:\n",
    "        print(\"Serializing {:d} examples into {}\".format(X.shape[0], result_tf_file))\n",
    "        \n",
    "    # iterate over each sample,\n",
    "    # and serialize it as ProtoBuf.\n",
    "    for idx in range(X.shape[0]):\n",
    "        x = X[idx]\n",
    "        if Y is not None:\n",
    "            y = Y[idx]\n",
    "        \n",
    "        d_feature = {}\n",
    "        d_feature['X'] = dtype_feature_x(x)\n",
    "        if Y is not None:\n",
    "            d_feature['Y'] = dtype_feature_y(y)\n",
    "            \n",
    "        features = tf.train.Features(feature=d_feature)\n",
    "        example = tf.train.Example(features=features)\n",
    "        serialized = example.SerializeToString()\n",
    "        writer.write(serialized)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Writing {} done!\".format(result_tf_file))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dg_jae(addr_X_file, addr_y_file, all_len, window_size, file_series, load_size):\n",
    "    \n",
    "    global I\n",
    "    h5f = {}\n",
    "    X_file = h5py.File(addr_X_file,'r')\n",
    "    y_file = h5py.File(addr_y_file,'r')\n",
    "\n",
    "    \n",
    "    flag = np.asarray(all_len)\n",
    "    print('flags_shape=', flag.shape)\n",
    "    r = []\n",
    "    r0 = []\n",
    "    r1 = []\n",
    "    flag_start = 0\n",
    "    k = 0\n",
    "    all_shape = 0\n",
    "    for I in range(len(flag)-1):\n",
    "        X = X_file['predicted_TSP_FFT' + file_series][flag[I]:flag[I+1],:]\n",
    "        \n",
    "        half_len = X.shape[1]//2\n",
    "        temp0 = X[:,0:half_len]\n",
    "        temp0 = preprocessing.normalize(temp0, norm='l2', axis=1, copy=True)\n",
    "        temp0 = np.concatenate((temp0,np.repeat(np.reshape(temp0[-1,:],(1,temp0.shape[1])),[window_size],axis=0)), axis=0)\n",
    "        temp0 = np.concatenate((np.repeat(np.reshape(temp0[0,:],(1,temp0.shape[1])),[window_size],axis=0),temp0), axis=0)\n",
    "\n",
    "        for i in range(0,temp0.shape[0]-2*window_size):\n",
    "            r0.append(np.ndarray.flatten(temp0[i:i+window_size*2+1,:]))\n",
    "                \n",
    "        temp1 = X[:,half_len:]\n",
    "        temp1 = preprocessing.normalize(temp1, norm='l2', axis=1, copy=True)\n",
    "        temp1 = np.concatenate((temp1,np.repeat(np.reshape(temp1[-1,:],(1,temp1.shape[1])),[window_size],axis=0)), axis=0)\n",
    "        temp1 = np.concatenate((np.repeat(np.reshape(temp1[0,:],(1,temp1.shape[1])),[window_size],axis=0),temp1), axis=0)\n",
    "\n",
    "        for i in range(0,temp1.shape[0]-2*window_size):\n",
    "            r1.append(np.ndarray.flatten(temp1[i:i+window_size*2+1,:]))       \n",
    "           \n",
    "        \n",
    "        \n",
    "        if np.asarray(r0).shape[0] > load_size:\n",
    "            r = np.concatenate((np.asarray(r0),np.asarray(r1)),axis=1)\n",
    "            y = y_file['Train2_TSP_clean_FFTs' + file_series][:,flag_start:flag_start + len(r)]\n",
    "            flag_start = r.shape[0] + 1\n",
    "            np_to_tfrecords(np.asarray(r), y.T, 'TSP/Organized/concatenated/TFr/dataset_context' + str(k), verbose=True)\n",
    "            print('r_shape=', r.shape)\n",
    "            all_shape = r.shape[0] + all_shape\n",
    "            r0 = []\n",
    "            r1 = []\n",
    "            k = k + 1\n",
    "            print('all_shape=',all_shape)\n",
    "   \n",
    "    \n",
    "    r = np.concatenate((np.asarray(r0),np.asarray(r1)),axis=1)\n",
    "    y = y_file['Train2_TSP_clean_FFTs' + file_series][:,flag_start:flag_start + len(r)]\n",
    "    flag_start = r.shape[0] + 1\n",
    "    np_to_tfrecords(np.asarray(r), y.T, 'TSP/Organized/concatenated/TFr/dataset_context' + str(k), verbose=True)\n",
    "    print('r_shape=', r.shape)\n",
    "    all_shape = r.shape[0] + all_shape\n",
    "    r0 = []\n",
    "    r1 = []\n",
    "    k = k + 1\n",
    "        \n",
    "    print('all_shape_full=', all_shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags_shape= (2401,)\n",
      "Serializing 11910 examples into TSP/Organized/concatenated/TFr/dataset_context0.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context0.tfrecords done!\n",
      "r_shape= (11910, 10250)\n",
      "all_shape= 11910\n",
      "Serializing 11913 examples into TSP/Organized/concatenated/TFr/dataset_context1.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context1.tfrecords done!\n",
      "r_shape= (11913, 10250)\n",
      "all_shape= 23823\n",
      "Serializing 11948 examples into TSP/Organized/concatenated/TFr/dataset_context2.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context2.tfrecords done!\n",
      "r_shape= (11948, 10250)\n",
      "all_shape= 35771\n",
      "Serializing 11925 examples into TSP/Organized/concatenated/TFr/dataset_context3.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context3.tfrecords done!\n",
      "r_shape= (11925, 10250)\n",
      "all_shape= 47696\n",
      "Serializing 11967 examples into TSP/Organized/concatenated/TFr/dataset_context4.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context4.tfrecords done!\n",
      "r_shape= (11967, 10250)\n",
      "all_shape= 59663\n",
      "Serializing 11908 examples into TSP/Organized/concatenated/TFr/dataset_context5.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context5.tfrecords done!\n",
      "r_shape= (11908, 10250)\n",
      "all_shape= 71571\n",
      "Serializing 11865 examples into TSP/Organized/concatenated/TFr/dataset_context6.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context6.tfrecords done!\n",
      "r_shape= (11865, 10250)\n",
      "all_shape= 83436\n",
      "Serializing 11985 examples into TSP/Organized/concatenated/TFr/dataset_context7.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context7.tfrecords done!\n",
      "r_shape= (11985, 10250)\n",
      "all_shape= 95421\n",
      "Serializing 11939 examples into TSP/Organized/concatenated/TFr/dataset_context8.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context8.tfrecords done!\n",
      "r_shape= (11939, 10250)\n",
      "all_shape= 107360\n",
      "Serializing 11920 examples into TSP/Organized/concatenated/TFr/dataset_context9.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context9.tfrecords done!\n",
      "r_shape= (11920, 10250)\n",
      "all_shape= 119280\n",
      "Serializing 11974 examples into TSP/Organized/concatenated/TFr/dataset_context10.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context10.tfrecords done!\n",
      "r_shape= (11974, 10250)\n",
      "all_shape= 131254\n",
      "Serializing 12007 examples into TSP/Organized/concatenated/TFr/dataset_context11.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context11.tfrecords done!\n",
      "r_shape= (12007, 10250)\n",
      "all_shape= 143261\n",
      "Serializing 12012 examples into TSP/Organized/concatenated/TFr/dataset_context12.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context12.tfrecords done!\n",
      "r_shape= (12012, 10250)\n",
      "all_shape= 155273\n",
      "Serializing 11924 examples into TSP/Organized/concatenated/TFr/dataset_context13.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context13.tfrecords done!\n",
      "r_shape= (11924, 10250)\n",
      "all_shape= 167197\n",
      "Serializing 11864 examples into TSP/Organized/concatenated/TFr/dataset_context14.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context14.tfrecords done!\n",
      "r_shape= (11864, 10250)\n",
      "all_shape= 179061\n",
      "Serializing 12000 examples into TSP/Organized/concatenated/TFr/dataset_context15.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context15.tfrecords done!\n",
      "r_shape= (12000, 10250)\n",
      "all_shape= 191061\n",
      "Serializing 12071 examples into TSP/Organized/concatenated/TFr/dataset_context16.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context16.tfrecords done!\n",
      "r_shape= (12071, 10250)\n",
      "all_shape= 203132\n",
      "Serializing 11947 examples into TSP/Organized/concatenated/TFr/dataset_context17.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context17.tfrecords done!\n",
      "r_shape= (11947, 10250)\n",
      "all_shape= 215079\n",
      "Serializing 12027 examples into TSP/Organized/concatenated/TFr/dataset_context18.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context18.tfrecords done!\n",
      "r_shape= (12027, 10250)\n",
      "all_shape= 227106\n",
      "Serializing 11983 examples into TSP/Organized/concatenated/TFr/dataset_context19.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context19.tfrecords done!\n",
      "r_shape= (11983, 10250)\n",
      "all_shape= 239089\n",
      "Serializing 11985 examples into TSP/Organized/concatenated/TFr/dataset_context20.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context20.tfrecords done!\n",
      "r_shape= (11985, 10250)\n",
      "all_shape= 251074\n",
      "Serializing 11972 examples into TSP/Organized/concatenated/TFr/dataset_context21.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context21.tfrecords done!\n",
      "r_shape= (11972, 10250)\n",
      "all_shape= 263046\n",
      "Serializing 12033 examples into TSP/Organized/concatenated/TFr/dataset_context22.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context22.tfrecords done!\n",
      "r_shape= (12033, 10250)\n",
      "all_shape= 275079\n",
      "Serializing 11932 examples into TSP/Organized/concatenated/TFr/dataset_context23.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context23.tfrecords done!\n",
      "r_shape= (11932, 10250)\n",
      "all_shape= 287011\n",
      "Serializing 11864 examples into TSP/Organized/concatenated/TFr/dataset_context24.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context24.tfrecords done!\n",
      "r_shape= (11864, 10250)\n",
      "all_shape= 298875\n",
      "Serializing 11968 examples into TSP/Organized/concatenated/TFr/dataset_context25.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context25.tfrecords done!\n",
      "r_shape= (11968, 10250)\n",
      "all_shape= 310843\n",
      "Serializing 11998 examples into TSP/Organized/concatenated/TFr/dataset_context26.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context26.tfrecords done!\n",
      "r_shape= (11998, 10250)\n",
      "all_shape= 322841\n",
      "Serializing 11861 examples into TSP/Organized/concatenated/TFr/dataset_context27.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context27.tfrecords done!\n",
      "r_shape= (11861, 10250)\n",
      "all_shape= 334702\n",
      "Serializing 11872 examples into TSP/Organized/concatenated/TFr/dataset_context28.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context28.tfrecords done!\n",
      "r_shape= (11872, 10250)\n",
      "all_shape= 346574\n",
      "Serializing 11907 examples into TSP/Organized/concatenated/TFr/dataset_context29.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context29.tfrecords done!\n",
      "r_shape= (11907, 10250)\n",
      "all_shape= 358481\n",
      "Serializing 11897 examples into TSP/Organized/concatenated/TFr/dataset_context30.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context30.tfrecords done!\n",
      "r_shape= (11897, 10250)\n",
      "all_shape= 370378\n",
      "Serializing 11887 examples into TSP/Organized/concatenated/TFr/dataset_context31.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context31.tfrecords done!\n",
      "r_shape= (11887, 10250)\n",
      "all_shape= 382265\n",
      "Serializing 11893 examples into TSP/Organized/concatenated/TFr/dataset_context32.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context32.tfrecords done!\n",
      "r_shape= (11893, 10250)\n",
      "all_shape= 394158\n",
      "Serializing 12001 examples into TSP/Organized/concatenated/TFr/dataset_context33.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context33.tfrecords done!\n",
      "r_shape= (12001, 10250)\n",
      "all_shape= 406159\n",
      "Serializing 11935 examples into TSP/Organized/concatenated/TFr/dataset_context34.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context34.tfrecords done!\n",
      "r_shape= (11935, 10250)\n",
      "all_shape= 418094\n",
      "Serializing 12028 examples into TSP/Organized/concatenated/TFr/dataset_context35.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context35.tfrecords done!\n",
      "r_shape= (12028, 10250)\n",
      "all_shape= 430122\n",
      "Serializing 11914 examples into TSP/Organized/concatenated/TFr/dataset_context36.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context36.tfrecords done!\n",
      "r_shape= (11914, 10250)\n",
      "all_shape= 442036\n",
      "Serializing 11886 examples into TSP/Organized/concatenated/TFr/dataset_context37.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context37.tfrecords done!\n",
      "r_shape= (11886, 10250)\n",
      "all_shape= 453922\n",
      "Serializing 11904 examples into TSP/Organized/concatenated/TFr/dataset_context38.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context38.tfrecords done!\n",
      "r_shape= (11904, 10250)\n",
      "all_shape= 465826\n",
      "Serializing 8556 examples into TSP/Organized/concatenated/TFr/dataset_context39.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset_context39.tfrecords done!\n",
      "r_shape= (8556, 10250)\n",
      "all_shape_full= 474382\n"
     ]
    }
   ],
   "source": [
    "qqq = dg_jae(addr_X_file, addr_y_file, all_len, 2, str(1), load_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 10250)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing 95074 examples into TSP/Organized/concatenated/TFr/dataset0.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset0.tfrecords done!\n",
      "Serializing 95074 examples into TSP/Organized/concatenated/TFr/dataset1.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset1.tfrecords done!\n",
      "Serializing 95074 examples into TSP/Organized/concatenated/TFr/dataset2.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset2.tfrecords done!\n",
      "Serializing 95074 examples into TSP/Organized/concatenated/TFr/dataset3.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset3.tfrecords done!\n",
      "Serializing 95074 examples into TSP/Organized/concatenated/TFr/dataset4.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset4.tfrecords done!\n",
      "Serializing 1 examples into TSP/Organized/concatenated/TFr/dataset5.tfrecords\n",
      "Writing TSP/Organized/concatenated/TFr/dataset5.tfrecords done!\n"
     ]
    }
   ],
   "source": [
    "# k = 0\n",
    "# for I in index:\n",
    "#     if data_len-I<load_size:\n",
    "#         X = X_file['Train_TSP_mixed_FFT' + file_series][:,I:]\n",
    "#         y = y_file['Train_TSP_clean_FFTs' + file_series][:,I:]\n",
    "#     else:\n",
    "#         X = X_file['Train_TSP_mixed_FFT' + file_series][:,I:I+load_size]\n",
    "#         y = y_file['Train_TSP_clean_FFTs' + file_series][:,I:I+load_size]\n",
    "# #     Normalization\n",
    "#     X = preprocessing.normalize(X, norm='l2', axis=0, copy=True)\n",
    "# #     Mask\n",
    "#     a = y[0:1025]\n",
    "#     b = y[1025:]\n",
    "#     Mask = a/(a+b)\n",
    "#     Mask = np.concatenate((Mask,b/(a+b)), axis = 0)\n",
    "#     np_to_tfrecords(X.T, Mask.T, 'TSP/Organized/concatenated/TFr/dataset' + str(k), verbose=True)\n",
    "#     k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
