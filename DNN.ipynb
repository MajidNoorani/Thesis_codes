{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN_A with 1025 input and 2050 output\n",
    "# DNN_C with 2050 input and 2050 output\n",
    "# Half of the data is used to train DNN_A and the other half is given to trained DNN_A to generate data for DNN_C\n",
    "# DNN_C has it's own cost function(customized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries.\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "# from separation import bss_eval_sources \n",
    "from pystoi.stoi import stoi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "# from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "import time\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read necessary files, contarins mixed and clean features.\n",
    "def data_reading(i):\n",
    "    temp = open( \"/home/majid/Codes/Thesis/TIMIT/Organized/concatenated/Mixed\" +str(i) + \".p\", \"rb\")\n",
    "    ftr = pickle.load( temp  ) .T\n",
    "    temp.close()\n",
    "    #contarins target(clean) log power features.\n",
    "    temp = open( \"/home/majid/Codes/Thesis/TIMIT/Organized/concatenated/clean\" +str(i) + \".p\", \"rb\")\n",
    "    target = pickle.load( temp ).T\n",
    "    temp.close()\n",
    "    return ftr, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr , target = data_reading(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116351, 2050)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ftr[0:100000]\n",
    "# y = target[0:100000]\n",
    "# X_test = ftr[100000:]\n",
    "# Y_test = target[100000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ftr\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_A = [1025,1025,1025]\n",
    "h_C = [4100, 4100, 4100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_C_loss(y_true,y_pred):\n",
    "    c = 0.2 # c is equal to lambda in the paper\n",
    "    term1 = K.sum(((y_true - y_pred)**2))\n",
    "    term2 = K.sum((y_true[0:1025] - y_pred[1025:2050])**2) + K.sum((y_true[1025:2050] - y_pred[0:1025])**2)\n",
    "    loss = term1 - c * term2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_A():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(h_A[0], input_dim = X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(h_A[1], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(h_A[2], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(y.shape[1], kernel_initializer='normal'))\n",
    "        # Compile model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_C():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(h_C[0], input_dim = X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(h_C[1], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(h_C[2], kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(y.shape[1], kernel_initializer='normal'))\n",
    "        # Compile model\n",
    "        model.compile(loss=DNN_C_loss, optimizer='adam')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 27s 533us/step - loss: 0.1828\n",
      "50000/50000 [==============================] - 5s 97us/step\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 26s 527us/step - loss: 0.1600\n",
      "50000/50000 [==============================] - 5s 102us/step\n",
      "Results: -0.15 (0.00) MSE\n",
      "Epoch 1/1\n",
      "100000/100000 [==============================] - 63s 632us/step - loss: 0.1522\n",
      "16351/16351 [==============================] - 2s 107us/step\n"
     ]
    }
   ],
   "source": [
    "# seed = 1\n",
    "# np.random.seed(seed)\n",
    "estimator_A = KerasRegressor(build_fn=DNN_A, epochs=1, batch_size=150, verbose=1)\n",
    "# kfold = KFold(n_splits=2, random_state=seed)\n",
    "kfold = KFold(n_splits=2)\n",
    "results = cross_val_score(estimator_A, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "estimator_A.fit(X, y)\n",
    "# prediction = estimator_A.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model you have trained\n",
    "estimator_A.model.save('/home/majid/Codes/Thesis/Models/Two_stage/trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "119115/119115 [==============================] - 74s 618us/step - loss: 0.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/keras/engine/sequential.py:110: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "120729/120729 [==============================] - 75s 625us/step - loss: 0.1195\n",
      "Epoch 1/1\n",
      "116935/116935 [==============================] - 74s 632us/step - loss: 0.1171\n"
     ]
    }
   ],
   "source": [
    "# fit the model with the first half of dataset\n",
    "for i in range(1,2):\n",
    "    estimator_A = load_model('/home/majid/Codes/Thesis/Models/Two_stage/trained_model.h5')\n",
    "    ftr , target = data_reading(i)\n",
    "    X = ftr\n",
    "    y = target\n",
    "    ftr = []\n",
    "    target = []\n",
    "    estimator_A.fit(X, y, epochs=1, batch_size=150)\n",
    "    estimator_A.model.save('/home/majid/Codes/Thesis/Models/Two_stage/trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# generating the second set of dataset\n",
    "for i in range(2,4):\n",
    "    estimator_A = load_model('/home/majid/Codes/Thesis/Models/Two_stage/trained_model.h5')\n",
    "    ftr , target = data_reading(i)\n",
    "    X_sec = ftr\n",
    "#     y_sec = target\n",
    "    ftr = []\n",
    "    target = []\n",
    "    prediction = estimator_A.predict(X_sec)\n",
    "    pickle.dump( prediction, open( \"/home/majid/Codes/Thesis/TIMIT/Organized/Two_stage_sec_set/new\"+str(i)+\".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint\n",
    "# # define the checkpoint\n",
    "# filepath = \"model.h5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.6880\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.68803, saving model to model.h5\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 0s 555us/step - loss: 0.2899\n",
      "\n",
      "Epoch 00002: loss improved from 1.68803 to 0.28990, saving model to model.h5\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 0s 540us/step - loss: 0.2072\n",
      "\n",
      "Epoch 00003: loss improved from 0.28990 to 0.20718, saving model to model.h5\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 0s 625us/step - loss: 0.1929\n",
      "\n",
      "Epoch 00004: loss improved from 0.20718 to 0.19287, saving model to model.h5\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 0s 514us/step - loss: 0.1905\n",
      "\n",
      "Epoch 00005: loss improved from 0.19287 to 0.19050, saving model to model.h5\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 0s 508us/step - loss: 0.1889\n",
      "\n",
      "Epoch 00006: loss improved from 0.19050 to 0.18888, saving model to model.h5\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 0s 506us/step - loss: 0.1864\n",
      "\n",
      "Epoch 00007: loss improved from 0.18888 to 0.18636, saving model to model.h5\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 0s 509us/step - loss: 0.1830\n",
      "\n",
      "Epoch 00008: loss improved from 0.18636 to 0.18300, saving model to model.h5\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 0s 505us/step - loss: 0.1788\n",
      "\n",
      "Epoch 00009: loss improved from 0.18300 to 0.17875, saving model to model.h5\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.1743\n",
      "\n",
      "Epoch 00010: loss improved from 0.17875 to 0.17434, saving model to model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f898f33b400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # fit the model\n",
    "# estimator_A.fit(X[300:600], y[300:600], epochs=10, batch_size=150, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.6880\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 0s 542us/step - loss: 0.2993\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 0s 567us/step - loss: 0.2086\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.1932\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.1905\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 0s 577us/step - loss: 0.1889\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 0s 578us/step - loss: 0.1864\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.1829\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 0s 576us/step - loss: 0.1787\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 0s 639us/step - loss: 0.1741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f898dcf1588>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "# estimator_A.fit(X[300:600], y[300:600])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
