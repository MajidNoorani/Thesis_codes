{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries.\n",
    "import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "from mir_eval import separation \n",
    "from pystoi.stoi import stoi \n",
    "import h5py\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from pypesq import pesq\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "import time\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "# from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(wave,angle):\n",
    "    recon1 = wave*np.cos(angle)+wave*np.sin(angle)*1j\n",
    "#     recon = np.sqrt(np.power(10, wave))\n",
    "#     recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=128, win_length=512, window='hann')\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:96: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "estimator_A = load_model('Models/Two_stage/512_3/saved-model-adam-046-0.0528.hdf5')\n",
    "name0 = '512_3_46'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 29014)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TSP/Organized/concatenated/Test_TSP_mixed_FFT'  + data_series + '.hdf5','r')\n",
    "data_shape = h5f['Test_TSP_mixed_FFT' + data_series].shape\n",
    "print(data_shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('TSP/Organized/concatenated/Test_all_len'  + data_series + '.hdf5','r')\n",
    "all_len = h5f['Test_all_len' + data_series][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "test_point_start0 = 0\n",
    "test_point_stop0 = data_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FM\n",
    "FM_test_point_start0 =  0\n",
    "FM_test_point_stop0 = all_len[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FF\n",
    "FF_test_point_start0 =  all_len[36]+1\n",
    "FF_test_point_stop0 = all_len[72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MM\n",
    "MM_test_point_start0 =  all_len[72] + 1\n",
    "MM_test_point_stop0 = data_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = [test_point_start0, test_point_stop0, FM_test_point_start0, FM_test_point_stop0, FF_test_point_start0, \n",
    "        FF_test_point_stop0, MM_test_point_start0, MM_test_point_stop0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_samples = 257"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "SR = 16000\n",
    "for i in range(0,len(indx),2):\n",
    "    test_point_start0 = indx[i]\n",
    "    test_point_stop0 = indx[i+1]\n",
    "    h5f = h5py.File('TSP/Organized/concatenated/Test_TSP_mixed_FFT'  + data_series + '.hdf5','r')\n",
    "    test_input = h5f['Test_TSP_mixed_FFT' + data_series][:, test_point_start0 : test_point_stop0]\n",
    "    h5f = h5py.File('TSP/Organized/concatenated/Test_TSP_clean_FFTs'  + data_series + '.hdf5','r')\n",
    "    test_target = h5f['Test_TSP_clean_FFTs' + data_series][:, test_point_start0 : test_point_stop0]\n",
    "    h5f = h5py.File('TSP/Organized/concatenated/Test_TSP_mixed_phase'  + data_series + '.hdf5','r')\n",
    "    mixed_phase = h5f['Test_TSP_mixed_phase' + data_series][:, test_point_start0 : test_point_stop0]\n",
    "    h5f = h5py.File('TSP/Organized/concatenated/Test_TSP_clean_phases'  + data_series + '.hdf5','r')\n",
    "    clean_phase = h5f['Test_TSP_clean_phases' + data_series][:, test_point_start0 : test_point_stop0]\n",
    "    norms = np.zeros(test_input.shape[1])\n",
    "    for j in range(test_input.shape[1]):\n",
    "        norms[j] = np.linalg.norm(test_input[:,j])\n",
    "    test_input = preprocessing.normalize(test_input, norm='l2', axis=0, copy=True)\n",
    "    prediction = estimator_A.predict(test_input.T)\n",
    "    test_input = np.multiply(test_input,norms)\n",
    "    prediction0 = np.multiply(test_input.T, prediction[:,0:fft_samples])\n",
    "    prediction1 = np.multiply(test_input.T, prediction[:,fft_samples:])\n",
    "    speaker1 = reconstruct(prediction0, mixed_phase.T) + 2.179366134322788e-06\n",
    "    speaker2 = reconstruct(prediction1, mixed_phase.T) + 2.179366134322788e-06\n",
    "    clean_recon1 = reconstruct(test_target[0:fft_samples,:].T, clean_phase[0:fft_samples,:].T) + 2.179366134322788e-06\n",
    "    clean_recon2 = reconstruct(test_target[fft_samples:,:].T, clean_phase[fft_samples:,:].T) + 2.179366134322788e-06\n",
    "    mixed_recon = reconstruct(test_input.T, mixed_phase.T) + 2.179366134322788e-06\n",
    "    if k == 0:\n",
    "        sf.write('TSP/Predicted/Voices/all_speaker1_' + name0 + '.wav', speaker1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/all_speaker2_' + name0 + '.wav', speaker2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/all_clean1_' + name0 + '.wav', clean_recon1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/all_clean2_' + name0 + '.wav', clean_recon2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/all_mixed_' + name0 + '.wav', mixed_recon, SR)\n",
    "    if k == 1:\n",
    "        sf.write('TSP/Predicted/Voices/FM_speaker1_' + name0 + '.wav', speaker1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FM_speaker2_' + name0 + '.wav', speaker2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FM_clean1_' + name0 + '.wav', clean_recon1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FM_clean2_' + name0 + '.wav', clean_recon2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FM_mixed_' + name0 + '.wav', mixed_recon, SR)\n",
    "    if k == 2:\n",
    "        sf.write('TSP/Predicted/Voices/FF_speaker1_' + name0 + '.wav', speaker1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FF_speaker2_' + name0 + '.wav', speaker2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FF_clean1_' + name0 + '.wav', clean_recon1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FF_clean2_' + name0 + '.wav', clean_recon2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/FF_mixed_' + name0 + '.wav', mixed_recon, SR)\n",
    "    if k == 3:\n",
    "        sf.write('TSP/Predicted/Voices/MM_speaker1_' + name0 + '.wav', speaker1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/MM_speaker2_' + name0 + '.wav', speaker2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/MM_clean1_' + name0 + '.wav', clean_recon1, SR)\n",
    "        sf.write('TSP/Predicted/Voices/MM_clean2_' + name0 + '.wav', clean_recon2, SR)\n",
    "        sf.write('TSP/Predicted/Voices/MM_mixed_' + name0 + '.wav', mixed_recon, SR)\n",
    "    k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
