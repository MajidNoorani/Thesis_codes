{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN_A with 1025 input and 2050 output\n",
    "# DNN_C with 2050 input and 2050 output\n",
    "# Half of the data is used to train DNN_A and the other half is given to trained DNN_A to generate data for DNN_C\n",
    "# DNN_C has it's own cost function(customized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries.\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "from mir_eval import separation \n",
    "from pystoi.stoi import stoi \n",
    "import h5py\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "import time\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "# from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read necessary files, contarins mixed and clean features.\n",
    "def data_reading(i):\n",
    "    temp = open( \"TIMIT/Organized/concatenated/Mixed\" +str(i) + \".p\", \"rb\")\n",
    "    ftr = pickle.load( temp  ) .T\n",
    "    temp.close()\n",
    "    #contarins target(clean) log power features.\n",
    "    temp = open( \"TIMIT/Organized/concatenated/clean\" +str(i) + \".p\", \"rb\")\n",
    "    target = pickle.load( temp ).T\n",
    "    temp.close()\n",
    "    return ftr, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_reading(i):\n",
    "    temp = open( \"TIMIT/Organized/concatenated/Mixed_phase\" +str(i) + \".p\", \"rb\")\n",
    "    angle = pickle.load( temp  ) .T\n",
    "    temp.close()\n",
    "    #contarins target(clean) log power features.\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_A = [1025,1025,1025]\n",
    "h_C = [4100, 4100, 4100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(wave,angle):\n",
    "    recon1 = wave*np.cos(angle)+wave*np.sin(angle)*1j\n",
    "#     recon = np.sqrt(np.power(10, wave))\n",
    "#     recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=512, win_length=2048, window='hann')\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "I=0\n",
    "def data_gen(batch_size, data_len):\n",
    "    global I\n",
    "    while True:             #this line is just because keras needs infinite generators\n",
    "        for I in range(0,data_len-batch_size,batch_size): \n",
    "            h5f = h5py.File('TIMIT/Organized/concatenated/mixed0.hdf5','r')\n",
    "            ftr = h5f['mixed0'][:,I:I+batch_size]\n",
    "            h5f.close()\n",
    "            h5f = h5py.File('TIMIT/Organized/concatenated/clean0.hdf5','r')\n",
    "            temp = h5f['clean0'][:,I:I+batch_size]\n",
    "            target = temp\n",
    "            h5f.close()\n",
    "            yield(ftr.T, target.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = data_reading(0)\n",
    "X_dim= 1025\n",
    "y_dim = 2050\n",
    "estimator_A = Sequential()\n",
    "estimator_A.add(Dense(h_A[0], input_dim = X_dim, kernel_initializer='normal', activation='relu'))\n",
    "estimator_A.add(Dense(h_A[1], kernel_initializer='normal', activation='relu'))\n",
    "estimator_A.add(Dense(h_A[2], kernel_initializer='normal', activation='relu'))\n",
    "estimator_A.add(Dense(y_dim, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "estimator_A.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LossHistory(keras.callbacks.Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.losses = []\n",
    "\n",
    "#     def on_batch_end(self, batch, logs={}):\n",
    "#         self.losses.append(logs.get('loss'))\n",
    "\n",
    "# history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/mixed0.hdf5','r')\n",
    "ftr_shape = h5f['mixed0'].shape\n",
    "h5f.close()\n",
    "batch_size = 128\n",
    "steps_per_epoch = int(ftr_shape[1]/(2*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/clean0.hdf5','r')\n",
    "clean_shape = h5f['clean0'][:,0:128]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2050, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 939485)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3669"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gg = data_gen(batch_size, int(ftr_shape[0]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1025)\n"
     ]
    }
   ],
   "source": [
    "# print(next(gg)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3669/3669 [==============================] - 105s 29ms/step - loss: 0.0055\n",
      "Epoch 2/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.2683e-04\n",
      "Epoch 3/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.3839e-04\n",
      "Epoch 4/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 7.5481e-05\n",
      "Epoch 5/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 5.5282e-05\n",
      "Epoch 6/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 6.3811e-05\n",
      "Epoch 7/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 3.2245e-05\n",
      "Epoch 8/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 2.9843e-05\n",
      "Epoch 9/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 2.1974e-05\n",
      "Epoch 10/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 2.0948e-05\n",
      "Epoch 11/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.9141e-05 1s \n",
      "Epoch 12/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.6864e-05\n",
      "Epoch 13/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.5824e-05\n",
      "Epoch 14/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 1.3252e-05\n",
      "Epoch 15/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.4268e-05\n",
      "Epoch 16/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.1260e-05\n",
      "Epoch 17/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 1.2067e-05\n",
      "Epoch 18/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 9.8468e-06\n",
      "Epoch 19/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 9.1498e-06\n",
      "Epoch 20/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 8.9371e-06\n",
      "Epoch 21/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 8.7238e-06\n",
      "Epoch 22/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 1.0232e-05\n",
      "Epoch 23/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 7.0393e-06\n",
      "Epoch 24/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 7.7322e-06\n",
      "Epoch 25/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 6.3419e-06\n",
      "Epoch 26/50\n",
      "3669/3669 [==============================] - 95s 26ms/step - loss: 6.4812e-06\n",
      "Epoch 27/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 9.1325e-06\n",
      "Epoch 28/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 6.1515e-06\n",
      "Epoch 29/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 5.9698e-06\n",
      "Epoch 30/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 5.7596e-06\n",
      "Epoch 31/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 5.3284e-06\n",
      "Epoch 32/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 5.2980e-06\n",
      "Epoch 33/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 4.7006e-06\n",
      "Epoch 34/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 4.4748e-06\n",
      "Epoch 35/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 7.5226e-06\n",
      "Epoch 36/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 4.5987e-06\n",
      "Epoch 37/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 1.0006e-05\n",
      "Epoch 38/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 5.3838e-06\n",
      "Epoch 39/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 4.5493e-06\n",
      "Epoch 40/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 4.4476e-06\n",
      "Epoch 41/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 4.0747e-06\n",
      "Epoch 42/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.8097e-06 0s - loss:\n",
      "Epoch 43/50\n",
      "3669/3669 [==============================] - 97s 26ms/step - loss: 3.7084e-06\n",
      "Epoch 44/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.7719e-06\n",
      "Epoch 45/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.5406e-06\n",
      "Epoch 46/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.9626e-06\n",
      "Epoch 47/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.2867e-06\n",
      "Epoch 48/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.1026e-06\n",
      "Epoch 49/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.9899e-06\n",
      "Epoch 50/50\n",
      "3669/3669 [==============================] - 96s 26ms/step - loss: 3.3657e-06\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "estimator_A.fit_generator(generator=data_gen(batch_size, int(ftr_shape[0]/2)),\n",
    "                          steps_per_epoch=steps_per_epoch, \n",
    "                          epochs=50,\n",
    "                          shuffle=True,\n",
    "                          verbose=1)\n",
    "toc  =time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_of_train = 79.79761300086975\n"
     ]
    }
   ],
   "source": [
    "print('time_of_train =', (toc - tic)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_A.save('Models/Two_stage/trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_A.save_weights('Models/Two_stage/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/majid/anaconda3/envs/Myenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "estimator_A = load_model('Models/Two_stage/trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_start0 = 1000\n",
    "test_point_stop0 = 1400\n",
    "\n",
    "test_point_start = 469750\n",
    "test_point_stop = 469850\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/mixed0.hdf5','r')\n",
    "test_input = h5f['mixed0'][:,test_point_start0 : test_point_stop0]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/clean0.hdf5','r')\n",
    "test_target = h5f['clean0'][:, test_point_start0 : test_point_stop0]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/phase0.hdf5','r')\n",
    "angle = h5f['phase0'][:,test_point_start0 : test_point_stop0]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 400)\n",
      "(2050, 400)\n",
      "(1025, 400)\n"
     ]
    }
   ],
   "source": [
    "print(test_input.shape)\n",
    "print(test_target.shape)\n",
    "print(angle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = estimator_A.predict(test_input.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2050)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = reconstruct(prediction[:,1025:2050], angle.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_recon = reconstruct(test_target[1025:2050,:].T, angle.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed_recon = reconstruct(test_input[0:1025,:].T, angle.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(s1*10, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(mixed_recon*10, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 300)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1025)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_recon = stoi(s1, clean_recon, 16000, extended=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282933397259574"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_mixed = stoi(mixed_recon, clean_recon, 16000, extended=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6989585388076244"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_recon, sir_recon, sar_recon, perm_recon = separation.bss_eval_sources(s1, clean_recon, compute_permutation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_mixed, sir_mixed, sar_mixed, perm_mixed = separation.bss_eval_sources(mixed_recon, clean_recon, compute_permutation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDR_recon= [16.44320281]\n",
      "SDR_mixed= [7.82182918]\n"
     ]
    }
   ],
   "source": [
    "print('SDR_recon=', sdr_recon)\n",
    "print('SDR_mixed=', sdr_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1025:2050"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
