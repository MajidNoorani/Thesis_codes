{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_FA = natsorted(np.squeeze([x[2] for x in os.walk('TSP/48k/FA')]))\n",
    "files_FB = natsorted(np.squeeze([x[2] for x in os.walk('TSP/48k/FB')]))\n",
    "files_MC = natsorted(np.squeeze([x[2] for x in os.walk('TSP/48k/MC')]))\n",
    "files_MD = natsorted(np.squeeze([x[2] for x in os.walk('TSP/48k/MD')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STFT(wavefile):\n",
    "    N = 2048\n",
    "    M = 512\n",
    "    frames = librosa.stft(wavefile, n_fft=2048, hop_length=M, win_length=N, window='hann', center=False)\n",
    "    data_phase=np.angle(frames)\n",
    "    return frames, data_phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 1 hour of training data we need 800 mixed files of each type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% of all data is for training - 10% valid - 10% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FA VS MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_number = 0\n",
    "chosen = []\n",
    "counter = 0\n",
    "file_series = str(0)\n",
    "while(mixed_number < 800):\n",
    "    while(True):\n",
    "        file1_indx = np.random.randint(0,(len(files_FA)-1) * 0.8) # 80%\n",
    "        file2_indx = np.random.randint(0,(len(files_MC)-1) * 0.8) # 80%\n",
    "        if str(file1_indx) + str('_') + str(file2_indx) not in chosen: # to prevent from choosing repeated files\n",
    "            chosen.append(str(file1_indx) + str('_') + str(file2_indx))\n",
    "            mixed_number += 1\n",
    "            break\n",
    "    wave1, samplerate = sf.read('TSP/48k/FA/' + files_FA[file1_indx])\n",
    "    wave2, samplerate = sf.read('TSP/48k/MC/' + files_MC[file2_indx])\n",
    "    if len(wave1) < len(wave2): # cropping data\n",
    "        mixed = wave1 + wave2[0:len(wave1)]\n",
    "        wave2 = wave2[0:len(wave1)]\n",
    "    else:\n",
    "        mixed = wave2 + wave1[0:len(wave2)]\n",
    "        wave1 = wave1[0:len(wave2)]\n",
    "    # framming and FFT and phase\n",
    "    mixed_FFT, mixed_phase = STFT(mixed)\n",
    "    wave1_FFT, wave1_phase = STFT(wave1)\n",
    "    wave2_FFT, wave2_phase = STFT(wave2)  \n",
    "    # concate wave 1 and wave 2 to have a 2 times dimention of each\n",
    "    clean_FFTs = np.concatenate((wave1_FFT, wave2_FFT), axis = 0)\n",
    "    clean_phases = np.concatenate((wave1_phase, wave2_phase), axis = 0)\n",
    "    \n",
    "    # writing files of TSP_mixed_FFT **** TSP_mixed_phase **** TSP_clean_FFTs **** TSP_clean_phases\n",
    "    if counter == 0:\n",
    "        with h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_FFT' + file_series + '.hdf5', \"w\") as f_mixed_FFT:\n",
    "                dset = f_mixed_FFT.create_dataset('Train_TSP_mixed_FFT' + file_series ,shape=(mixed_FFT.shape[0],0), maxshape=(mixed_FFT.shape[0],100000000),\n",
    "                                chunks=True)\n",
    "        with h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_phase' + file_series + '.hdf5', \"w\") as f_mixed_phase:\n",
    "                dset = f_mixed_phase.create_dataset('Train_TSP_mixed_phase' + file_series ,shape=(mixed_phase.shape[0],0), maxshape=(mixed_phase.shape[0],100000000),\n",
    "                                chunks=True)\n",
    "        with h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs' + file_series + '.hdf5', \"w\") as f_clean_FFTs:\n",
    "                dset = f_clean_FFTs.create_dataset('Train_TSP_clean_FFTs' + file_series ,shape=(clean_FFTs.shape[0],0), maxshape=(clean_FFTs.shape[0],100000000),\n",
    "                                chunks=True)\n",
    "        with h5py.File('TSP/Organized/concatenated/Train_TSP_clean_phases' + file_series + '.hdf5', \"w\") as f_clean_phases:\n",
    "                dset = f_clean_phases.create_dataset('Train_TSP_clean_phases' + file_series ,shape=(clean_phases.shape[0],0), maxshape=(clean_phases.shape[0],100000000),\n",
    "                                chunks=True)\n",
    "\n",
    "    # mixed_FFT\n",
    "    f_mixed_FFT = h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_FFT' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_mixed_FFT['Train_TSP_mixed_FFT' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + mixed_FFT.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(mixed_FFT)\n",
    "    f_mixed_FFT.close() \n",
    "    \n",
    "    # mixed_phase\n",
    "    f_mixed_phase = h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_phase' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_mixed_phase['Train_TSP_mixed_phase' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + mixed_phase.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(mixed_phase)\n",
    "    f_mixed_phase.close() \n",
    "    \n",
    "    # clean_FFTs\n",
    "    f_clean_FFTs = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_clean_FFTs['Train_TSP_clean_FFTs' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + clean_FFTs.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(clean_FFTs)\n",
    "    f_clean_FFTs.close() \n",
    "    \n",
    "    # clean_phases\n",
    "    f_clean_phases = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_phases' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_clean_phases['Train_TSP_clean_phases' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + clean_phases.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(clean_phases)\n",
    "    f_clean_phases.close() \n",
    "    \n",
    "\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TSP/Organized/concatenated/Train_selected_FA_MC.txt', 'w') as f:\n",
    "    for item in chosen:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2050, 154781)\n"
     ]
    }
   ],
   "source": [
    "a = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs'  + file_series + '.hdf5','r')\n",
    "data_shape = a['Train_TSP_clean_FFTs' + file_series].shape\n",
    "print(data_shape)\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FA VS FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_number = 0\n",
    "chosen = []\n",
    "counter = 0\n",
    "file_series = str(0)\n",
    "while(mixed_number < 800):\n",
    "    while(True):\n",
    "        file1_indx = np.random.randint(0,(len(files_FA)-1) * 0.8) # 80%\n",
    "        file2_indx = np.random.randint(0,(len(files_FB)-1) * 0.8) # 80%\n",
    "        if str(file1_indx) + str('_') + str(file2_indx) not in chosen: # to prevent from choosing repeated files\n",
    "            chosen.append(str(file1_indx) + str('_') + str(file2_indx))\n",
    "            mixed_number += 1\n",
    "            break\n",
    "    wave1, samplerate = sf.read('TSP/48k/FA/' + files_FA[file1_indx])\n",
    "    wave2, samplerate = sf.read('TSP/48k/FB/' + files_FB[file2_indx])\n",
    "    if len(wave1) < len(wave2): # cropping data\n",
    "        mixed = wave1 + wave2[0:len(wave1)]\n",
    "        wave2 = wave2[0:len(wave1)]\n",
    "    else:\n",
    "        mixed = wave2 + wave1[0:len(wave2)]\n",
    "        wave1 = wave1[0:len(wave2)]\n",
    "    # framming and FFT and phase\n",
    "    mixed_FFT, mixed_phase = STFT(mixed)\n",
    "    wave1_FFT, wave1_phase = STFT(wave1)\n",
    "    wave2_FFT, wave2_phase = STFT(wave2)  \n",
    "    # concate wave 1 and wave 2 to have a 2 times dimention of each\n",
    "    clean_FFTs = np.concatenate((wave1_FFT, wave2_FFT), axis = 0)\n",
    "    clean_phases = np.concatenate((wave1_phase, wave2_phase), axis = 0)\n",
    "    \n",
    "    # writing files of TSP_mixed_FFT **** TSP_mixed_phase **** TSP_clean_FFTs **** TSP_clean_phases\n",
    "\n",
    "    # mixed_FFT\n",
    "    f_mixed_FFT = h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_FFT' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_mixed_FFT['Train_TSP_mixed_FFT' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + mixed_FFT.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(mixed_FFT)\n",
    "    f_mixed_FFT.close() \n",
    "    \n",
    "    # mixed_phase\n",
    "    f_mixed_phase = h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_phase' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_mixed_phase['Train_TSP_mixed_phase' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + mixed_phase.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(mixed_phase)\n",
    "    f_mixed_phase.close() \n",
    "    \n",
    "    # clean_FFTs\n",
    "    f_clean_FFTs = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_clean_FFTs['Train_TSP_clean_FFTs' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + clean_FFTs.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(clean_FFTs)\n",
    "    f_clean_FFTs.close() \n",
    "    \n",
    "    # clean_phases\n",
    "    f_clean_phases = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_phases' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_clean_phases['Train_TSP_clean_phases' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + clean_phases.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(clean_phases)\n",
    "    f_clean_phases.close() \n",
    "    \n",
    "\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TSP/Organized/concatenated/Train_selected_FA_FB.txt', 'w') as f:\n",
    "    for item in chosen:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2050, 317109)\n"
     ]
    }
   ],
   "source": [
    "a = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs'  + file_series + '.hdf5','r')\n",
    "data_shape = a['Train_TSP_clean_FFTs' + file_series].shape\n",
    "print(data_shape)\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MC VS MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_number = 0\n",
    "chosen = []\n",
    "counter = 0\n",
    "file_series = str(0)\n",
    "while(mixed_number < 800):\n",
    "    while(True):\n",
    "        file1_indx = np.random.randint(0,(len(files_MC)-1) * 0.8) # 80%\n",
    "        file2_indx = np.random.randint(0,(len(files_MD)-1) * 0.8) # 80%\n",
    "        if str(file1_indx) + str('_') + str(file2_indx) not in chosen: # to prevent from choosing repeated files\n",
    "            chosen.append(str(file1_indx) + str('_') + str(file2_indx))\n",
    "            mixed_number += 1\n",
    "            break\n",
    "    wave1, samplerate = sf.read('TSP/48k/MC/' + files_MC[file1_indx])\n",
    "    wave2, samplerate = sf.read('TSP/48k/MD/' + files_MD[file2_indx])\n",
    "    if len(wave1) < len(wave2): # cropping data\n",
    "        mixed = wave1 + wave2[0:len(wave1)]\n",
    "        wave2 = wave2[0:len(wave1)]\n",
    "    else:\n",
    "        mixed = wave2 + wave1[0:len(wave2)]\n",
    "        wave1 = wave1[0:len(wave2)]\n",
    "    # framming and FFT and phase\n",
    "    mixed_FFT, mixed_phase = STFT(mixed)\n",
    "    wave1_FFT, wave1_phase = STFT(wave1)\n",
    "    wave2_FFT, wave2_phase = STFT(wave2)  \n",
    "    # concate wave 1 and wave 2 to have a 2 times dimention of each\n",
    "    clean_FFTs = np.concatenate((wave1_FFT, wave2_FFT), axis = 0)\n",
    "    clean_phases = np.concatenate((wave1_phase, wave2_phase), axis = 0)\n",
    "    \n",
    "    # writing files of TSP_mixed_FFT **** TSP_mixed_phase **** TSP_clean_FFTs **** TSP_clean_phases\n",
    "\n",
    "    # mixed_FFT\n",
    "    f_mixed_FFT = h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_FFT' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_mixed_FFT['Train_TSP_mixed_FFT' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + mixed_FFT.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(mixed_FFT)\n",
    "    f_mixed_FFT.close() \n",
    "    \n",
    "    # mixed_phase\n",
    "    f_mixed_phase = h5py.File('TSP/Organized/concatenated/Train_TSP_mixed_phase' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_mixed_phase['Train_TSP_mixed_phase' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + mixed_phase.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(mixed_phase)\n",
    "    f_mixed_phase.close() \n",
    "    \n",
    "    # clean_FFTs\n",
    "    f_clean_FFTs = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_clean_FFTs['Train_TSP_clean_FFTs' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + clean_FFTs.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(clean_FFTs)\n",
    "    f_clean_FFTs.close() \n",
    "    \n",
    "    # clean_phases\n",
    "    f_clean_phases = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_phases' + file_series + '.hdf5', 'r+')     # open the file\n",
    "    dset = f_clean_phases['Train_TSP_clean_phases' + file_series]                # load the data\n",
    "    dset_shape = dset.shape\n",
    "    dset.resize(dset_shape[1] + clean_phases.shape[1], axis=1)  \n",
    "    dset[:,dset_shape[1]:] = np.abs(clean_phases)\n",
    "    f_clean_phases.close() \n",
    "    \n",
    "\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TSP/Organized/concatenated/Train_selected_MC_MD.txt', 'w') as f:\n",
    "    for item in chosen:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2050, 475371)\n"
     ]
    }
   ],
   "source": [
    "a = h5py.File('TSP/Organized/concatenated/Train_TSP_clean_FFTs'  + file_series + '.hdf5','r')\n",
    "data_shape = a['Train_TSP_clean_FFTs' + file_series].shape\n",
    "print(data_shape)\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
