{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.initializers import glorot_normal\n",
    "# import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "from mir_eval import separation \n",
    "from pystoi.stoi import stoi \n",
    "import h5py\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "import time\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "# from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_DNNC(y_true, y_pred, Lambda = 0.05):\n",
    "    loss = K.sum(K.square(y_true - y_pred)) \n",
    "    - Lambda * K.sum(K.square(y_true[0:257,:] - y_pred[0:257,:]) + K.square(y_true[257:,:] - y_pred[257:,:]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(wave,angle):\n",
    "    recon1 = wave*np.cos(angle)+wave*np.sin(angle)*1j\n",
    "#     recon = np.sqrt(np.power(10, wave))\n",
    "#     recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=160, win_length=400, window='hann')\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = str(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 295522)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/Two_stage_sec_set/predicted_sec_set.hdf5','r')\n",
    "X = h5f['predicted_sec_set'][:]\n",
    "h5f.close()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 295522)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/clean'  + data_series + '_sec.hdf5','r')\n",
    "y = h5f['clean'  + data_series + '_sec'][:]\n",
    "h5f.close()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55383, 257)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/valid_mixed'  + data_series + '.hdf5','r')\n",
    "X_valid = h5f['valid_mixed'  + data_series ][:]\n",
    "h5f.close()\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55383, 514)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TIMIT/Organized/concatenated/valid_clean'  + data_series + '.hdf5','r')\n",
    "y_valid = h5f['valid_clean'  + data_series ][:]\n",
    "h5f.close()\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.121167555"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing.normalize(X, norm='l2', axis=0, copy=True)\n",
    "y_train = preprocessing.normalize(y, norm='l2', axis=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = preprocessing.normalize(X_valid, norm='l2', axis=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_A = load_model('Models/Two_stage/trained_model19.h5')\n",
    "prediction = estimator_A.predict(X_valid)\n",
    "prediction0 = np.multiply(X_valid, prediction[:,0:257])\n",
    "prediction1 = np.multiply(X_valid, prediction[:,257:])\n",
    "X_valid = np.concatenate((prediction0, prediction1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = preprocessing.normalize(X_valid, norm='l2', axis=0, copy=True)\n",
    "y_valid = preprocessing.normalize(y_valid, norm='l2', axis=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 295522)\n",
      "(514, 295522)\n",
      "(55383, 514)\n",
      "(55383, 514)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim= 514\n",
    "y_dim = 514\n",
    "h_C = [1028, 1028, 1028]\n",
    "def DNN_C():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h_C[0], input_dim = X_dim, kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(h_C[1], kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(h_C[2], kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(y_dim, kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^^^^^^^^^^^ Training on mixed5^^^^^^^^^^^^^^^^^^^^^\n",
      "Train on 295522 samples, validate on 55383 samples\n",
      "Epoch 1/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0349 - val_loss: 4.9948e-05\n",
      "Epoch 2/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0286 - val_loss: 0.0017\n",
      "Epoch 3/200\n",
      "295522/295522 [==============================] - 21s 73us/step - loss: 0.0276 - val_loss: 0.0012\n",
      "Epoch 4/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0269 - val_loss: 5.5100e-04\n",
      "Epoch 5/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0264 - val_loss: 3.0740e-04\n",
      "Epoch 6/200\n",
      "295522/295522 [==============================] - 21s 71us/step - loss: 0.0260 - val_loss: 7.3724e-04\n",
      "Epoch 7/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0256 - val_loss: 9.4125e-04\n",
      "Epoch 8/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0254 - val_loss: 9.0416e-04\n",
      "Epoch 9/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0251 - val_loss: 0.0012\n",
      "Epoch 10/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0249 - val_loss: 6.9995e-04\n",
      "Epoch 11/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0247 - val_loss: 8.1126e-04\n",
      "Epoch 12/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0245 - val_loss: 0.0017\n",
      "Epoch 13/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0243 - val_loss: 0.0011\n",
      "Epoch 14/200\n",
      "295522/295522 [==============================] - 21s 73us/step - loss: 0.0241 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0240 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0238 - val_loss: 0.0015\n",
      "Epoch 17/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0237 - val_loss: 0.0015\n",
      "Epoch 18/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0236 - val_loss: 9.6672e-04\n",
      "Epoch 19/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0235 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0233 - val_loss: 0.0018\n",
      "Epoch 21/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0232 - val_loss: 0.0015\n",
      "Epoch 22/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0231 - val_loss: 0.0015\n",
      "Epoch 23/200\n",
      "295522/295522 [==============================] - 24s 80us/step - loss: 0.0230 - val_loss: 0.0015\n",
      "Epoch 24/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0229 - val_loss: 0.0014\n",
      "Epoch 25/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0228 - val_loss: 9.9230e-04\n",
      "Epoch 26/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0227 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0226 - val_loss: 0.0020\n",
      "Epoch 28/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0225 - val_loss: 0.0015\n",
      "Epoch 29/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0224 - val_loss: 0.0016\n",
      "Epoch 30/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0223 - val_loss: 0.0012\n",
      "Epoch 31/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0222 - val_loss: 0.0014\n",
      "Epoch 32/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0221 - val_loss: 0.0017\n",
      "Epoch 33/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0220 - val_loss: 0.0016\n",
      "Epoch 34/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0219 - val_loss: 0.0016\n",
      "Epoch 35/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0219 - val_loss: 0.0017\n",
      "Epoch 36/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0217 - val_loss: 0.0016\n",
      "Epoch 37/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0217 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0216 - val_loss: 0.0020\n",
      "Epoch 39/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0215 - val_loss: 0.0018\n",
      "Epoch 40/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0214 - val_loss: 0.0014\n",
      "Epoch 41/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0214 - val_loss: 0.0018\n",
      "Epoch 42/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0213 - val_loss: 0.0018\n",
      "Epoch 43/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0212 - val_loss: 0.0014\n",
      "Epoch 44/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0211 - val_loss: 0.0014\n",
      "Epoch 45/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0210 - val_loss: 0.0013\n",
      "Epoch 46/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0210 - val_loss: 0.0017\n",
      "Epoch 47/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0209 - val_loss: 0.0019\n",
      "Epoch 48/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0208 - val_loss: 0.0013\n",
      "Epoch 49/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0207 - val_loss: 0.0017\n",
      "Epoch 50/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0206 - val_loss: 0.0014\n",
      "Epoch 51/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0206 - val_loss: 0.0016\n",
      "Epoch 52/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0205 - val_loss: 0.0016\n",
      "Epoch 53/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0204 - val_loss: 0.0016\n",
      "Epoch 54/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0203 - val_loss: 0.0015\n",
      "Epoch 55/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0203 - val_loss: 0.0017\n",
      "Epoch 56/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0202 - val_loss: 0.0017\n",
      "Epoch 57/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0201 - val_loss: 0.0017\n",
      "Epoch 58/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0200 - val_loss: 0.0017\n",
      "Epoch 59/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0200 - val_loss: 0.0014\n",
      "Epoch 60/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0200 - val_loss: 0.0015\n",
      "Epoch 61/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0199 - val_loss: 0.0018\n",
      "Epoch 62/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0198 - val_loss: 0.0019\n",
      "Epoch 63/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0198 - val_loss: 0.0018\n",
      "Epoch 64/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0197 - val_loss: 0.0013\n",
      "Epoch 65/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0196 - val_loss: 0.0017\n",
      "Epoch 66/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0196 - val_loss: 0.0014\n",
      "Epoch 67/200\n",
      "295522/295522 [==============================] - 21s 73us/step - loss: 0.0195 - val_loss: 0.0014\n",
      "Epoch 68/200\n",
      "295522/295522 [==============================] - 24s 81us/step - loss: 0.0195 - val_loss: 0.0015\n",
      "Epoch 69/200\n",
      "295522/295522 [==============================] - 24s 81us/step - loss: 0.0194 - val_loss: 0.0017\n",
      "Epoch 70/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0194 - val_loss: 0.0015\n",
      "Epoch 71/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0193 - val_loss: 0.0016\n",
      "Epoch 72/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0192 - val_loss: 0.0014\n",
      "Epoch 73/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0192 - val_loss: 0.0013\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0191 - val_loss: 0.0017\n",
      "Epoch 75/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0191 - val_loss: 0.0021\n",
      "Epoch 76/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0190 - val_loss: 0.0020\n",
      "Epoch 77/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0190 - val_loss: 0.0017\n",
      "Epoch 78/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0189 - val_loss: 0.0019\n",
      "Epoch 79/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0189 - val_loss: 0.0015\n",
      "Epoch 80/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0188 - val_loss: 0.0012\n",
      "Epoch 81/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0188 - val_loss: 0.0015\n",
      "Epoch 82/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0187 - val_loss: 0.0012\n",
      "Epoch 83/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0187 - val_loss: 0.0019\n",
      "Epoch 84/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0187 - val_loss: 0.0016\n",
      "Epoch 85/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0186 - val_loss: 0.0017\n",
      "Epoch 86/200\n",
      "295522/295522 [==============================] - 24s 82us/step - loss: 0.0185 - val_loss: 0.0015\n",
      "Epoch 87/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0185 - val_loss: 0.0016\n",
      "Epoch 88/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0184 - val_loss: 0.0016\n",
      "Epoch 89/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0184 - val_loss: 0.0015\n",
      "Epoch 90/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0184 - val_loss: 0.0016\n",
      "Epoch 91/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0183 - val_loss: 0.0016\n",
      "Epoch 92/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0183 - val_loss: 0.0016\n",
      "Epoch 93/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0182 - val_loss: 0.0016\n",
      "Epoch 94/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0183 - val_loss: 0.0019\n",
      "Epoch 95/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0181 - val_loss: 0.0013\n",
      "Epoch 96/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0181 - val_loss: 0.0013\n",
      "Epoch 97/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0181 - val_loss: 0.0016\n",
      "Epoch 98/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0180 - val_loss: 0.0016\n",
      "Epoch 99/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0180 - val_loss: 0.0015\n",
      "Epoch 100/200\n",
      "295522/295522 [==============================] - 21s 73us/step - loss: 0.0180 - val_loss: 0.0018\n",
      "Epoch 101/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0180 - val_loss: 0.0018\n",
      "Epoch 102/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0179 - val_loss: 0.0015\n",
      "Epoch 103/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0179 - val_loss: 0.0016\n",
      "Epoch 104/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0178 - val_loss: 0.0019\n",
      "Epoch 105/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0178 - val_loss: 0.0013\n",
      "Epoch 106/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0177 - val_loss: 0.0017\n",
      "Epoch 107/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0178 - val_loss: 0.0016\n",
      "Epoch 108/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0177 - val_loss: 0.0016\n",
      "Epoch 109/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0176 - val_loss: 0.0018\n",
      "Epoch 110/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0177 - val_loss: 0.0018\n",
      "Epoch 111/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0176 - val_loss: 0.0018\n",
      "Epoch 112/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0176 - val_loss: 0.0013\n",
      "Epoch 113/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0175 - val_loss: 0.0016\n",
      "Epoch 114/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0175 - val_loss: 0.0015\n",
      "Epoch 115/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0175 - val_loss: 0.0015\n",
      "Epoch 116/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0175 - val_loss: 0.0016\n",
      "Epoch 117/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0174 - val_loss: 0.0015\n",
      "Epoch 118/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0174 - val_loss: 0.0016\n",
      "Epoch 119/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0173 - val_loss: 0.0016\n",
      "Epoch 120/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0173 - val_loss: 0.0016\n",
      "Epoch 121/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0173 - val_loss: 0.0014\n",
      "Epoch 122/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0172 - val_loss: 0.0017\n",
      "Epoch 123/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0173 - val_loss: 0.0018\n",
      "Epoch 124/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0172 - val_loss: 0.0020\n",
      "Epoch 125/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0172 - val_loss: 0.0016\n",
      "Epoch 126/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0172 - val_loss: 0.0015\n",
      "Epoch 127/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0171 - val_loss: 0.0016\n",
      "Epoch 128/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0171 - val_loss: 0.0016\n",
      "Epoch 129/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0171 - val_loss: 0.0012\n",
      "Epoch 130/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0170 - val_loss: 0.0016\n",
      "Epoch 131/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0170 - val_loss: 0.0013\n",
      "Epoch 132/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0170 - val_loss: 0.0019\n",
      "Epoch 133/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0170 - val_loss: 0.0016\n",
      "Epoch 134/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0169 - val_loss: 0.0018\n",
      "Epoch 135/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0169 - val_loss: 0.0015\n",
      "Epoch 136/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0169 - val_loss: 0.0016\n",
      "Epoch 137/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0168 - val_loss: 0.0014\n",
      "Epoch 138/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0168 - val_loss: 0.0019\n",
      "Epoch 139/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0168 - val_loss: 0.0013\n",
      "Epoch 140/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0168 - val_loss: 0.0017\n",
      "Epoch 141/200\n",
      "295522/295522 [==============================] - 24s 82us/step - loss: 0.0168 - val_loss: 0.0014\n",
      "Epoch 142/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0167 - val_loss: 0.0014\n",
      "Epoch 143/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0171 - val_loss: 0.0017\n",
      "Epoch 144/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0167 - val_loss: 0.0018\n",
      "Epoch 145/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0167 - val_loss: 0.0014\n",
      "Epoch 146/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0167 - val_loss: 0.0015\n",
      "Epoch 147/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0167 - val_loss: 0.0015\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0169 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0166 - val_loss: 0.0018\n",
      "Epoch 150/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0166 - val_loss: 0.0015\n",
      "Epoch 151/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0166 - val_loss: 0.0012\n",
      "Epoch 152/200\n",
      "295522/295522 [==============================] - 24s 82us/step - loss: 0.0165 - val_loss: 0.0017\n",
      "Epoch 153/200\n",
      "295522/295522 [==============================] - 24s 80us/step - loss: 0.0165 - val_loss: 0.0014\n",
      "Epoch 154/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0165 - val_loss: 0.0012\n",
      "Epoch 155/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0165 - val_loss: 0.0015\n",
      "Epoch 156/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0166 - val_loss: 0.0015\n",
      "Epoch 157/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0165 - val_loss: 0.0017\n",
      "Epoch 158/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0164 - val_loss: 0.0015\n",
      "Epoch 159/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0164 - val_loss: 0.0017\n",
      "Epoch 160/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0164 - val_loss: 0.0013\n",
      "Epoch 161/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0164 - val_loss: 0.0016\n",
      "Epoch 162/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0164 - val_loss: 0.0017\n",
      "Epoch 163/200\n",
      "295522/295522 [==============================] - 23s 78us/step - loss: 0.0164 - val_loss: 0.0015\n",
      "Epoch 164/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0164 - val_loss: 0.0014\n",
      "Epoch 165/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0163 - val_loss: 0.0012\n",
      "Epoch 166/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0163 - val_loss: 0.0018\n",
      "Epoch 167/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0162 - val_loss: 0.0016\n",
      "Epoch 168/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0163 - val_loss: 0.0015\n",
      "Epoch 169/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0162 - val_loss: 0.0016\n",
      "Epoch 170/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0162 - val_loss: 0.0017\n",
      "Epoch 171/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0165 - val_loss: 0.0016\n",
      "Epoch 172/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0162 - val_loss: 0.0010\n",
      "Epoch 173/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0162 - val_loss: 0.0014\n",
      "Epoch 174/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0161 - val_loss: 0.0017\n",
      "Epoch 175/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0161 - val_loss: 0.0015\n",
      "Epoch 176/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0161 - val_loss: 0.0014\n",
      "Epoch 177/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0161 - val_loss: 0.0017\n",
      "Epoch 178/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0161 - val_loss: 0.0016\n",
      "Epoch 179/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0160 - val_loss: 0.0013\n",
      "Epoch 180/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0161 - val_loss: 0.0014\n",
      "Epoch 181/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0160 - val_loss: 0.0015\n",
      "Epoch 182/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0160 - val_loss: 0.0013\n",
      "Epoch 183/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0160 - val_loss: 0.0015\n",
      "Epoch 184/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0161 - val_loss: 0.0016\n",
      "Epoch 185/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0160 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0160 - val_loss: 0.0016\n",
      "Epoch 187/200\n",
      "295522/295522 [==============================] - 21s 72us/step - loss: 0.0159 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "295522/295522 [==============================] - 22s 74us/step - loss: 0.0159 - val_loss: 0.0015\n",
      "Epoch 189/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0159 - val_loss: 0.0015\n",
      "Epoch 190/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0159 - val_loss: 0.0016\n",
      "Epoch 191/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0158 - val_loss: 0.0016\n",
      "Epoch 192/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0158 - val_loss: 0.0017\n",
      "Epoch 193/200\n",
      "295522/295522 [==============================] - 22s 73us/step - loss: 0.0158 - val_loss: 0.0017\n",
      "Epoch 194/200\n",
      "295522/295522 [==============================] - 22s 76us/step - loss: 0.0158 - val_loss: 0.0015\n",
      "Epoch 195/200\n",
      "295522/295522 [==============================] - 21s 73us/step - loss: 0.0158 - val_loss: 0.0015\n",
      "Epoch 196/200\n",
      "295522/295522 [==============================] - 23s 79us/step - loss: 0.0158 - val_loss: 0.0015\n",
      "Epoch 197/200\n",
      "295522/295522 [==============================] - 22s 75us/step - loss: 0.0158 - val_loss: 0.0016\n",
      "Epoch 198/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0157 - val_loss: 0.0019\n",
      "Epoch 199/200\n",
      "295522/295522 [==============================] - 23s 77us/step - loss: 0.0159 - val_loss: 0.0013\n",
      "Epoch 200/200\n",
      "295522/295522 [==============================] - 23s 76us/step - loss: 0.0157 - val_loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "tic = time.time()\n",
    "estimator_C = KerasRegressor(build_fn=DNN_C, epochs = 200, batch_size=batch_size, shuffle = True, verbose=1)\n",
    "# kfold = KFold(n_splits=2, random_state=None)\n",
    "# kfold = KFold(n_splits=5)\n",
    "# results = cross_val_score(estimator_A, X.T, y.T, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "# toc_fold = time.time()\n",
    "\n",
    "print(\"^^^^^^^^^^^^^^^^^^^^^ Training on mixed5^^^^^^^^^^^^^^^^^^^^^\")\n",
    "# filepath=\"half_trained.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 0, save_best_only = True, mode = 'min') \n",
    "# callbacks_list = [checkpoint]\n",
    "history = estimator_C.fit(X.T, y.T, validation_data=(X_valid, y_valid), shuffle = True, batch_size=batch_size,  steps_per_epoch=None)\n",
    "toc_adam = time.time()\n",
    "# print(\"---------------------------second part of training---------------------------\")\n",
    "# new_model = load_model(filepath)\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save?_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "# new_model.optimizer = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# new_model.fit(X.T, Mask.T, shuffle = True, epochs = 100, batch_size=100,  steps_per_epoch=None, callbacks=callbacks_list)\n",
    "# estimator_A.fit (X.T, y.T, shuffle = True, batch_size=100,  steps_per_epoch=None, callbacks = [changer])\n",
    "# prediction = estimator_A.predict(X_test)\n",
    "\n",
    "toc_fit = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_C.model.save('Models/Two_stage/Model1_C0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU9bn48c+TmexkIQtbAiQBZFeQiFj3WhG1iq0bVq1trUurtcu9tnjb3tvrr4t289pWW7FSlbohSsu9arFWcWcJiLJL2BO27Ps2yfP743sCQ0ggA0wmwPN+vfLKzPcs85wzZ77P+X7PJqqKMcYY011RkQ7AGGPM8cUShzHGmJBY4jDGGBMSSxzGGGNCYonDGGNMSCxxGGOMCYklDmPCSESeFJGfdnPcrSLyuaOdjzHhZonDGGNMSCxxGGOMCYklDnPS87qI7hWRT0SkTkSeEJH+IvKaiNSIyBsi0jdo/CtFZI2IVIrIIhEZHTRsoois8KZ7AYjr8FmfF5GV3rQfiMipRxjzbSJSKCLlIrJARAZ55SIiD4nIXhGpFpFVIjLOG3aZiKz1YisWkX8/ohVmTnqWOIxxrgYuBk4BrgBeA/4DyMT9Tu4BEJFTgOeA73jDXgX+V0RiRCQG+BswB0gDXvTmizftRGA2cAeQDjwGLBCR2FACFZHPAr8ArgMGAtuA573BU4HzvOVI8cYp84Y9AdyhqknAOODNUD7XmHaWOIxxfq+qe1S1GHgXWKKqH6lqIzAfmOiNdz3wiqr+U1VbgF8D8cBngClANPA/qtqiqvOAZUGfcTvwmKouUdVWVX0KaPKmC8WNwGxVXaGqTcB9wFkikgO0AEnAKEBUdZ2q7vKmawHGiEiyqlao6ooQP9cYwBKHMe32BL1u6OR9H+/1INwePgCq2gbsALK8YcV64J1DtwW9Hgr8m9dNVSkilcBgb7pQdIyhFteqyFLVN4E/AI8Ae0Vklogke6NeDVwGbBORt0XkrBA/1xjAEocxodqJSwCAO6aAq/yLgV1AllfWbkjQ6x3Az1Q1NegvQVWfO8oYEnFdX8UAqvo7VZ0EjMF1Wd3rlS9T1elAP1yX2twQP9cYwBKHMaGaC1wuIheJSDTwb7jupg+AD4EAcI+IRIvIF4HJQdM+DtwpImd6B7ETReRyEUkKMYbngK+KyATv+MjPcV1rW0XkDG/+0UAd0Ai0ecdgbhSRFK+LrRpoO4r1YE5iljiMCYGqbgBuAn4PlOIOpF+hqs2q2gx8EfgKUI47HvJy0LQFwG24rqQKoNAbN9QY3gB+DLyEa+UMA2Z4g5NxCaoC151VBvzKG3YzsFVEqoE7ccdKjAmZ2IOcjDHGhMJaHMYYY0JiicMYY0xILHEYY4wJiSUOY4wxIfFHOoCekJGRoTk5OZEOwxhjjivLly8vVdXMjuUnReLIycmhoKAg0mEYY8xxRUS2dVZuXVXGGGNCYonDGGNMSCxxGGOMCclJcYyjMy0tLRQVFdHY2BjpUMIqLi6O7OxsoqOjIx2KMeYEEdbEISLTgIcBH/BnVX2gw/BY4GlgEu6eOtd7N2qbDMxqHw34iarO96bZCtQArUBAVfOPJLaioiKSkpLIycnhwJuZnjhUlbKyMoqKisjNzY10OMaYE0TYuqpExId7JsCluNs73yAiYzqMditQoarDgYeAB73y1UC+qk4ApgGPiUhwkrtQVSccadIAaGxsJD09/YRNGgAiQnp6+gnfqjLG9KxwHuOYDBSq6mbvrqHPA9M7jDMdeMp7PQ+4SEREVetVNeCVxwFhuRPjiZw02p0My2iM6VnhTBxZuAfXtCvyyjodx0sUVbgH0uA9U2ANsAq4MyiRKPC6iCwXkdvDGD+ltU1U1jeH8yOMMea402vPqvKeyzwWOAO4T0TivEHnqOrpuC6wu0TkvM6mF5HbRaRARApKSkqOKIbyumaqGlqOaNrDqays5NFHHw15ussuu4zKysowRGSMMd0TzsRRjHukZrtsr6zTcbxjGCm4g+T7qOo6oBYY571vfzzmXmA+Bz5hLXi6Waqar6r5mZkHXTHfLVEitLaF53klXSWOQCDQydj7vfrqq6SmpoYlJmOM6Y5wJo5lwAgRyRWRGNwTyhZ0GGcBcIv3+hrgTVVVbxo/gIgMBUbhnlyW2P6YTe85y1NxB9LDIkogXM+5mjlzJps2bWLChAmcccYZnHvuuVx55ZWMGePOH7jqqquYNGkSY8eOZdasWfumy8nJobS0lK1btzJ69Ghuu+02xo4dy9SpU2loaAhPsMYYEyRsp+OqakBE7gYW4k7Hna2qa0TkfqBAVRcATwBzRKQQ96jN9sdfngPMFJEW3HORv6mqpSKSB8z3Dvj6gWdV9R9HG+t//+8a1u6sPqi8saUVBeKjfSHPc8ygZP7rirFdDn/ggQdYvXo1K1euZNGiRVx++eWsXr1632mzs2fPJi0tjYaGBs444wyuvvpq0tPTD5jHxo0bee6553j88ce57rrreOmll7jppptCjtUYY0IR1us4VPVV4NUOZf8Z9LoRuLaT6eYAczop3wycduwj7ZwIaFvPfNbkyZMPuNbid7/7HfPnzwdgx44dbNy48aDEkZuby4QJEwCYNGkSW7du7ZlgjTEntZP2yvFgXbUMisrrqWkKMHpgcthjSExM3Pd60aJFvPHGG3z44YckJCRwwQUXdHotRmxs7L7XPp/PuqqMMT2i155V1RtERQltYTrIkZSURE1NTafDqqqq6Nu3LwkJCaxfv57FixeHJQZjjDkS1uI4BBFoC1NXVXp6OmeffTbjxo0jPj6e/v377xs2bdo0/vSnPzF69GhGjhzJlClTwhOEMcYcAdFwnTbUi+Tn52vHBzmtW7eO0aNHH3K6PdWN7KluZFxWClHH8RXY3VlWY4zpSESWd3ZrJ+uqOoT2ZNEWpms5jDHmeGSJ4xCivEaG5Q1jjNnPEschRHmZ42TozjPGmO6yxHEI+7qqLHEYY8w+ljgOwbqqjDHmYJY4DsFaHMYYczBLHIfQmxJHnz59Ih2CMcYAljgOaV9XVQ/dr8oYY44HduX4IbSfVRWOFsfMmTMZPHgwd911FwA/+clP8Pv9vPXWW1RUVNDS0sJPf/pTpk/v+LRdY4yJLEscAK/NhN2rDir2o+Q1tRLjjwJfiI2zAePh0ge6HHz99dfzne98Z1/imDt3LgsXLuSee+4hOTmZ0tJSpkyZwpVXXmnPDTfG9CqWOCJk4sSJ7N27l507d1JSUkLfvn0ZMGAA3/3ud3nnnXeIioqiuLiYPXv2MGDAgEiHa4wx+1jigC5bBgJsKa4io08MA1Pij/nHXnvttcybN4/du3dz/fXX88wzz1BSUsLy5cuJjo4mJyen09upG2NMJFniOIwoCd91HNdffz233XYbpaWlvP3228ydO5d+/foRHR3NW2+9xbZt28LzwcYYcxQscRxGlEjYbnI4duxYampqyMrKYuDAgdx4441cccUVjB8/nvz8fEaNGhWWzzXGmKNhieMwoiR8D3MCWLVq/0H5jIwMPvzww07Hq62tDVsMxhgTCruO4zDC2VVljDHHo7AmDhGZJiIbRKRQRGZ2MjxWRF7whi8RkRyvfLKIrPT+PhaRL3R3nsdauFscxhhzvAlb4hARH/AIcCkwBrhBRMZ0GO1WoEJVhwMPAQ965auBfFWdAEwDHhMRfzfn2W3duV16VJQc17dVP55jN8b0TuFscUwGClV1s6o2A88DHS+Dng485b2eB1wkIqKq9aoa8MrjgPbarzvz7Ja4uDjKysoOW7FGhfG54+GmqpSVlREXFxfpUIwxJ5BwHhzPAnYEvS8CzuxqHFUNiEgVkA6UisiZwGxgKHCzN7w78wRARG4HbgcYMmTIQcOzs7MpKiqipKTkkAtRXtdMc6CN1orjs/KNi4sjOzs70mEYY04gvfasKlVdAowVkdHAUyLyWojTzwJmAeTn5x/UrIiOjiY3N/ew8/nR31bx6qq9rPjxxaF8vDHGnLDC2VVVDAwOep/tlXU6joj4gRSgLHgEVV0H1ALjujnPYyohxk99c+DwIxpjzEkinIljGTBCRHJFJAaYASzoMM4C4Bbv9TXAm6qq3jR+ABEZCowCtnZznsdUXLSPxpa2sF0EaIwxx5uwdVV5xyTuBhYCPmC2qq4RkfuBAlVdADwBzBGRQqAclwgAzgFmikgL0AZ8U1VLATqbZ7iWASAhxgdAQ0sribG9tmfPGGN6TFhrQlV9FXi1Q9l/Br1uBK7tZLo5wJzuzjOc2hNHfbMlDmOMAbty/LDio70WR3NrhCMxxpjewRLHYSTEuFZGfYsdIDfGGLDEcVgDU931G5v21kU4EmOM6R0scRzGqVkp9In1815haaRDMcaYXsESx2H4fVFMyUvnfUscxhgDWOLolnNHZLC9vJ7tZfWRDsUYYyLOEkc3nD08A8C6q4wxBksc3TIsM5EByXG88+mhb4hojDEnA0sc3SAiTBs3gDfX76W8rjnS4RhjTERZ4uimGyYPobm1jZdXFEU6FGOMiShLHN00ckASk4b25dml2+2pesaYk5oljhDcMHkIm0vqeHejHSQ3xpy8LHGE4IrTBpKVGs+vX99grQ5jzEnLEkcIYv0+vvO5EXxSVMU/Vu+OdDjGGBMRljhC9MXTsxnRrw8/f20dtU1240NjzMnHEkeIfFHCz74wnqKKBn72yrpIh2OMMT3OEscRmJybxu3n5vHc0u28vsa6rIwxJxdLHEfoe1NPYXxWCv8292O2ltot140xJw9LHEco1u/j0RtPx+cTvv50AXtrGiMdkjHG9IiwJg4RmSYiG0SkUERmdjI8VkRe8IYvEZEcr/xiEVkuIqu8/58NmmaRN8+V3l+/cC7DoQxOS+BPN02iuKKBGY8tZldVQ6RCMcaYHhO2xCEiPuAR4FJgDHCDiIzpMNqtQIWqDgceAh70ykuBK1R1PHALMKfDdDeq6gTvb2+4lqE7puSlM+fWyeytaeK6xz5kR7ndet0Yc2ILZ4tjMlCoqptVtRl4HpjeYZzpwFPe63nARSIiqvqRqu70ytcA8SISG8ZYj0p+ThrPfP1MqhsCXP3HD1i+rSLSIRljTNiEM3FkATuC3hd5ZZ2Oo6oBoApI7zDO1cAKVW0KKvuL1031YxGRzj5cRG4XkQIRKSgpCf/t0E8bnMoLd0whNjqKGbM+5Jkl2+zqcmPMCalXHxwXkbG47qs7gopv9LqwzvX+bu5sWlWdpar5qpqfmZkZ/mCBUQOS+d+7z+EzwzL44fzV/OClT2hsae2RzzbGmJ4SzsRRDAwOep/tlXU6joj4gRSgzHufDcwHvqyqm9onUNVi738N8CyuS6zXSE2IYfZXzuCezw5nbkGRHfcwxpxwwpk4lgEjRCRXRGKAGcCCDuMswB38BrgGeFNVVURSgVeAmar6fvvIIuIXkQzvdTTweWB1GJfhiPiihO9NHcnjX85nS0kdUx96h8ff2UygtS3SoRljzFELW+LwjlncDSwE1gFzVXWNiNwvIld6oz0BpItIIfA9oP2U3buB4cB/djjtNhZYKCKfACtxLZbHw7UMR+viMf1Z+N3zOHt4Oj97dR3TH3mfVUVVkQ7LGGOOipwMB3Dz8/O1oKAgYp+vqry2ejf/tWANZbVNfOUzuXzjgmFkJvXaE8WMMQYRWa6q+R3L/ZEI5mQjIlw2fiBnD8/ggdfW85cPtvDXJdu4dlI2t52bR05GYqRDNMaYbrMWRwRsLqnl8Xc389LyYlra2rh03ADuOG8Ypw1OjXRoxhizT1ctDkscEbS3ppEn39/KnMXbqGkMcFZeOnecn8f5p2TSxeUpxhjTYyxx9MLE0a62KcBzS7bzxHtb2F3dyKgBSdx5/jAuP3Ug0b5efamNMeYEZomjFyeOds2BNv6+sphZ72xm495aslLj+dKZQ/jc6P6MHJAU6fCMMScZSxzHQeJo19amvLVhL4+9vZmlW8sBd0uTr52dw6XjBhLjt1aIMSb8LHEcR4kj2O6qRv6xehdPfbiNLaV19E+O5br8wVw7aTBD0hMiHZ4x5gRmieM4TRzt2tqUtz8t4ckPtvLOxhJUYUpeGtdOGsyl4weQEGNnVhtjji1LHMd54gi2s7KBl1cU8eLyIraV1RPjj2Li4FQuGz+QqyZkkZIQHekQjTEnAEscJ1DiaKeqLNtawetrdvNeYSnrd9cQ64/isvEDuXBUP07LTmFoul1caIw5Mnbl+AlIRJicm8bk3DQAVhdX8cKyHfzto2Lmf+RuRHz6kFRmnDGEy08dSGKsfd3GmKNnLY4TUHOgjcK9tbxfWMrzy7azqaSOWH8UIwckceHIfnz17BxSE2IiHaYxppezrqqTKHEEU1WWb6vgH6t3s6q4iiVbyomLjmJ4vz5MzknnxilDGJbZJ9JhGmN6IUscJ2ni6Gj97mrmLiti494aFm8uo6VVOXt4OldNyGLS0L7kZiTa7U6MMYAlDkscnSipaWJuwQ6eXbKd4soGAFITojkrL51r87OZnJtOHzsuYsxJyxKHJY4utbUphSW1fLS9ghXbKnlj3R7K6poBOKV/H6ZPyOKqiVlkpcZHOFJjTE+yxGGJo9uaA228v6mUNcVVvPNpKUu3liMCp2alkJORyMVj+nPpuIH4oqxLy5gTmSUOSxxHbEd5PfM/KubDTWVsKqllb00TWanxnD8yk0lD+nLa4FSG97MD7MacaCxxWOI4JlrblNfX7OalFcUs3lxGbVMAgIlDUrlwZD/yMhM5Ky+d9D72WFxjjneWOCxxHHOB1ja2lNbx9qclvLBsBxv31gIgAmfmpnHjmUM5b0Sm3QLFmONURBKHiEwDHgZ8wJ9V9YEOw2OBp4FJQBlwvapuFZGLgQeAGKAZuFdV3/SmmQQ8CcQDrwLf1sMshCWOntHY0sqG3TW8tWEvLxYUUVzZgAjkZiRySr8kPjM8nQtH9mNwmt3V15jjQY8nDhHxAZ8CFwNFwDLgBlVdGzTON4FTVfVOEZkBfEFVrxeRicAeVd0pIuOAhaqa5U2zFLgHWIJLHL9T1dcOFYsljp7X2qYs21rO0i3lrNlZxZqd1RRVuFN+h2UmcsHIflw4sh9n5PalqqGFKBEyrHvLmF4lEveqmgwUqupmL4DngenA2qBxpgM/8V7PA/4gIqKqHwWNswaI91onaUCyqi725vk0cBVwyMRhep4vSpiSl86UvHTAXcG+pbSORRtKeGvDXuZ8uI0n3tuCP0oItCkxvii+ccEwpk8YRHbfBHtYlTG9WDgTRxawI+h9EXBmV+OoakBEqoB0oDRonKuBFaraJCJZ3nyC55nV2YeLyO3A7QBDhgw5isUwx4KIkJfZh7zMPnztnFzqmwN8uKmMpVvK6Zccx8c7Knn4Xxt5+F8bEYFBKfGcmZfG508dSH5OGslxdpzEmN6iV18WLCJjgQeBqaFOq6qzgFnguqqOcWjmKCXE+LlodH8uGt1/X9kd5+exflcN28vr2VRSyz/X7OHlFcWIwKgByZyR05fJuWkMSUsgJT6aIWkJdnsUYyIgnImjGBgc9D7bK+tsnCIR8QMpuIPkiEg2MB/4sqpuCho/+zDzNMepsYNSGDsoZd/7xpZWlm+rYNnWcgq2VjBveRFPf7ht3/D0xBjOzEtjSl46Z+amM6JfH6LsokRjwi6ciWMZMEJEcnGV+wzgSx3GWQDcAnwIXAO8qaoqIqnAK8BMVX2/fWRV3SUi1SIyBXdw/MvA78O4DCaC4qJ9nD08g7OHZwDQ0trG2p3VlNQ0UVLbxLIt5SzeXMarq3YDkBzn57TBqUwcnMqEIamclp1q15MYEwbhPh33MuB/cKfjzlbVn4nI/UCBqi4QkThgDjARKAdmqOpmEfkRcB+wMWh2U1V1r4jks/903NeAb9npuCcvVaWoooHFm8tYsb2Cj7ZX8umeGtq8LWJwWjynZqcydlAyYwYmM2ZQMv2S4iIbtDHHCbsA0BLHSaOuKcCq4io+3lHJyh2VrCqu2ncqMLgurqQ4P2mJMUwdO4Azc9MYOSCJhJhefcjPmB5nj441J43EWP8BpwIDVNW3sG53NWt3VrNhdw0NLa1sLavjgdfWA+CPEiYOSSU3I5E+sdEkxflJivOTmRTLZ0f1I8nO6jJmH0sc5qSQkhB9UDIB2FnZwOriKj7aUckHm8p4+9MSahsD1DW37hsnPtrHuSMymDAklQnZqYwZlGyP3jUntW4lDhH5NvAXoAb4M+6YxExVfT2MsRkTdoNS4xmUGs/UsQMOKG9tU2qbAhTurWXe8iI+3FTK62v37BveNyGa3IxEcjP6kJeZSG5GInmZieSkJ1Je14zfJ3YsxZywutvi+JqqPiwilwB9gZtxB7UtcZgTki9KSImPZtLQvkwa2heAirpmPimuYuOeGjaX1rGlpI73C0t5aUVRp9N/cWIWp/RPQgQyk2IZl5VCnj2a15wAups42rf0y4A5qrpGbOs3J5m+iTGcf0om55+SeUB5XVOALaV1bC6tY2tpHWmJMRTureXZpdtpDrQdMG6/pFjOGpZOVmo8Mf4oYv0+BqXGMXpgMnkZifh9dqsV0/t1N3EsF5HXgVzgPhFJAtoOM40xJ4XEWD/jslIYl5VyQPnMS0cRaFNaW5Xd1Y2s2F7BB5vK+HBTGeV1zQTaDjyjMcYfRb+kWJLjojltcCqnZqcwMCWOraV1BNqUU/oncWZeGrF+X08unjEH6dbpuCISBUwANqtqpYikAdmq+km4AzwW7HRc0xu1tSlNgTa2ldexbpc746u0tpmyumY+2l5BTWPgoGn6JkQzemAyu6oaGTMombOHZTAwNY6BKXEMSI4jJT7ausLMMXO0p+OeBaxU1ToRuQk4HfecDWPMEYqKEuJjfIwakMyoAcl8YeL+Ya1tys7KBnZWNpCTkUi0L4qPd1Qyb0URReX1jOjXhyWby3nlk10HzDPWH8WAlDhSE2JoDrRxalYKl586kFh/FANT4hmcFm+JxRy17rY4PgFOA07FXbX9Z+A6VT0/rNEdI9biMCeitjZlZ1UDe6ob2VXVyO6qRvZUN7K7usl7xgks2VxOQ8v+U4sTY3xE+6PonxTH+OwUBvdNYFdVA6t3VnHRqP5MnzCIQanxxPqjLMGYo25xBLx7SE0H/qCqT4jIrcc2RGNMKKKihOy+CWT37fqJirVNAT7eUQnA1rI6Nu6ppU2V7eX1vP1pCSU1TSTF+hnWr8++29q3y0yK5dzhGSTE+ogSoX+y6xIbnJbAqAFJx+SiyI93VLK7upFLOpwObXq37iaOGhG5D3ca7rneMQ+7lNaYXq5PrH/fTSLb/wdrbGnFHyX4fVFsKqllxbYK9tY00RRwz5N/t7CUtjalpbWN6g7HXFIToklLjCExxk9CjI/k+GiGpiWQm5nI0LRE0vvE0DchhuR4P82BNhJi/Ac8oKu4soGbn1hCbVOAF+88i0lD0w6Yf2V9M79/s5DLxg84aJiJrO52VQ3A3dl2maq+KyJDgAtU9elwB3gsWFeVMUevvjnA7qpGtpXVs3ZXNbuqGqioa6G+2V1pX1nfzLayepoCnZ9wGRcdxYTBqaQnxpKaEM0nRVVsLqklJT6aaH8UP5g2irjoKPonx7G6uIrf/auQ4soG0hJjeOWecxiYEt/DS2yO+iaHItIfOMN7u1RV9x7D+MLKEocxPaOtzZ16vL28noq6ZirqW6hubCHGF8WOinpW7qikuqGFsrpmGppb+eU1p9I/OY6b/rzkoNOT8zIT+fZFI/iPl1fRNzGG9MQY+iW7a176xPqIi/YRH+2jf3IcA1LiaA608ezS7bS2KldNzCI/py/Rdl3MUTmqxCEi1wG/AhbhLgY8F7hXVecd4zjDwhKHMb1PoLVt3wWPe6obqaxvoa45QHFFAyP692Fk/yREhDfX7+GRtzaREOOjqKKBLaV1Xc4zPtqHL0qobQoQH+1jSFoC0X5hcN8E+ie7W8D0T44jo0/MvoP/SXF+Juek0Tex6/uP7alu5M6/Lie7bwIPXXfaSXOh5tEmjo+Bi9tbGSKSCbyhqqcd80jDwBKHMSeOltY2GltaaQq0UdcUYE91E3uqG6lvDjB1zADion28tWEvS7eUs6uqgaZAG9vL6imtbUIVapoOvj4GICnWT0KsjwTvmE1ijJ/4GB+JsT5Wbq+ktK6Z5kAb10zK5ounZxHr9xEXHUVmUiw+EaoaWhiclnBCtXKONnGsUtXxQe+jgI+Dy3ozSxzGmHa1TQHKa5tpP9t4T3UjS7aUU1rbRENzK3XNrdQ3Bahvbt13/CY+2scvvjieV1ft4tFFm7qcd2KMjxH9k0iI8dEvKRZfVBRbSmsZlBpPXkYiraoMTIknKc5PwdYKsvvGc8nYAfRNjCEhxtfrks7RJo5f4a7heM4ruh74RFV/cEyjDBNLHMaYY0FVWb+7hsr6Fppb22hoDlBS00SgTekT6+fjokq2ltbT0NLK7qpGWlrbyMlIpLiigeLKBqKEfU+nTIjxUR90+36AaJ8QH+0jMymWQanx+L2bbQ5JTyQ+2ke0T/BHCT5fFNFRQrTPnUyQFOenpjFAXmYifp+wcM0e8jISOSsvnaioI78e51gcHL8aONt7+66qzj/iaHqYJQ5jTKS1tSkisLOqkcr6Zkb2T9r32OPapgANza3Ut7TS0NzKnupGdlY10tamlNc1U1zZcPgP8IhAe7Wem5HIC3dMOeJb/B/1EwBV9SXgpSP6dGOMOcm17/lnpcaTlepOLc7JSCQnI/Gw07a0thFoVVra3P+A97850MauqkZqmwIkxvpYv6uG6sYWpo0bwLpd1bz7aSmZfWKP+bIcssUhIjVAZyMIoKqafMiZi0zD3dPKB/xZVR/oMDwWeBqYBJQB16vqVhFJB+bhTv99UlXvDppmETAQaE/BUw93arC1OIwxJnRH1OJQ1aSj+EAf8AhwMVAELBORBaq6Nmi0W4EKVR0uIjOAB3HHTxqBHwPjvL+OblRVywTGGBMB4TyEPxkoVNXNqtoMPA9M7zDOdOAp7/U84CIREVWtU9X3cAnEGGNMLxLOxJEF7Ah6X+SVdTqOqgaAKiC9G/P+i4isFJEfd/UkQhG5XUQKRLVjOgwAABoISURBVKSgpKQk9OiNMcZ0qnedNNw9N3rXj5zr/d3c2UiqOktV81U1PzMzs7NRjDHGHIFwJo5iYHDQ+2yvrNNxRMQPpOAOkndJVYu9/zXAs7guMWOMMT0knIljGTBCRHJFJAaYASzoMM4C4Bbv9TXAm3qI07xExC8iGd7raODzwOpjHrkxxpgudfs6jlCpakBE7gYW4k7Hna2qa0TkfqBAVRcATwBzRKQQKMclFwBEZCuQDMSIyFXAVGAbsNBLGj7gDeDxcC2DMcaYg3X7yvHjmV3HYYwxoevqOo7j8eC4McaYCLLEYYwxJiSWOIwxxoTEEocxxpiQWOIwxhgTEkscxhhjQmKJwxhjTEgscRhjjAmJJQ5jjDEhscRhjDEmJJY4jDHGhMQShzHGmJBY4jDGGBMSSxzGGGNCYonDGGNMSCxxGGOMCYklDmOMMSGxxGGMMSYkljiMMcaEJKyJQ0SmicgGESkUkZmdDI8VkRe84UtEJMcrTxeRt0SkVkT+0GGaSSKyypvmdyIi4VwGY4wxBwpb4hARH/AIcCkwBrhBRMZ0GO1WoEJVhwMPAQ965Y3Aj4F/72TWfwRuA0Z4f9OOffTGGGO6Es4Wx2SgUFU3q2oz8DwwvcM404GnvNfzgItERFS1TlXfwyWQfURkIJCsqotVVYGngavCuAzGGGM6CGfiyAJ2BL0v8so6HUdVA0AVkH6YeRYdZp4AiMjtIlIgIgUlJSUhhm6MMaYrJ+zBcVWdpar5qpqfmZkZ6XCMMeaEEc7EUQwMDnqf7ZV1Oo6I+IEUoOww88w+zDyNMcaEUTgTxzJghIjkikgMMANY0GGcBcAt3utrgDe9YxedUtVdQLWITPHOpvoy8PdjH7oxxpiu+MM1Y1UNiMjdwELAB8xW1TUicj9QoKoLgCeAOSJSCJTjkgsAIrIVSAZiROQqYKqqrgW+CTwJxAOveX/GGGN6iBxiB/+EkZ+frwUFBZEOwxhjjisislxV8zuWn7AHx40xxoSHJQ5jjDEhscRhjDEmJJY4jDHGhMQShzHGmJBY4jDGGBMSSxzGGGNCYonDGGNMSCxxGGOMCYklDmOMMSGxxGGMMSYkljiMMcaExBKHMcaYkFjiMMYYExJLHMYYY0JiicMYY0xILHEYY4wJiSUOY4wxIbHEYYwxJiSWOIwxxoQkrIlDRKaJyAYRKRSRmZ0MjxWRF7zhS0QkJ2jYfV75BhG5JKh8q4isEpGVIlIQzviNMcYczB+uGYuID3gEuBgoApaJyAJVXRs02q1AhaoOF5EZwIPA9SIyBpgBjAUGAW+IyCmq2upNd6GqloYrdmOMMV0LZ4tjMlCoqptVtRl4HpjeYZzpwFPe63nARSIiXvnzqtqkqluAQm9+xhhjIiyciSML2BH0vsgr63QcVQ0AVUD6YaZV4HURWS4it3f14SJyu4gUiEhBSUnJUS2IMcaY/Y7Hg+PnqOrpwKXAXSJyXmcjqeosVc1X1fzMzMyejdAYY05g4UwcxcDgoPfZXlmn44iIH0gByg41raq2/98LzMe6sIwxpkeFM3EsA0aISK6IxOAOdi/oMM4C4Bbv9TXAm6qqXvkM76yrXGAEsFREEkUkCUBEEoGpwOowLoMxxpgOwnZWlaoGRORuYCHgA2ar6hoRuR8oUNUFwBPAHBEpBMpxyQVvvLnAWiAA3KWqrSLSH5jvjp/jB55V1X+EaxmMMcYcTNwO/oktPz9fCwrskg9jjAmFiCxX1fyO5cfjwXFjjDERZInDGGNMSCxxGGOMCYklDmOMMSGxxGGMMSYkljiMMcaExBKHMcaYkFjiMMYYExJLHMYYY0JiicOc2BqroeRTaA1EOhJjThiWOI5X5ZvhD5Nhzd+OfB6V2+HFr8KOpaFNpwqtLUf+uYeyfTF8+Ci0NBz9vFoa4MnL4ZEz4IEhsGa+Kz9c7G2thx5+OKoQaD6yaQPNsGOZm0dPaqyG//02vHbQE5671tYGdWWHmW8VvP8wBJqOLj7TPa0tUBv+5w9Z4jic1hZYu8D9SI5E8XJoqun++Esfd3+H0lwHz98EpRvg9R93XUl1rHxU95e1tcL8O2HNy/CXS6HgL658/avw3A0w98tQsuHgeW55F/58EfxmZGgbaGsLbH0PVs2DTxfCtg+gvjxoeAAW/hBmT4OF98GjU2D3Ki/WLtZ9zW5oqOh62V/5N9j9CVz4Q+g3yi3vwh/CL7LhzZ91Pt3HL8CDubB5UfeXreNyPv8lePTMQ1eWxcvhr9fAI1NcogRoaYQXboInPgfrX9m/HMG2fQj//C+3LHO+AP/33aNLMqpu+37sXFj+JCz5o9sGumPRL+A3p8Dyp1yy++TFg1t27/0P/PM/YZU37NOFB26vlTvg/d/B3++Gsk2df876V9yy1gU9LXr7Yrfz1JVD7XjU7nXbTkdb3oHnb4SqogPLy7fAJ3Ohuf7gaYK3YYC969wOypHuOBxKzW4ofAM2vdX5zk9TLTx1Bfz+9APXVRiE7e64J4z1/wcvfgW++Dicel1o09aVwhNTYcKX4Mrfdz6OKri7/boNeuF/QGszxPeFwWdCfRkkZkJK0MMT//X/oGQdnP1ttzf31k9dMjn1ehg82c3zrZ/DB7+DYRfBwFPdnt/ql6GhHPr0h6SBULQUpj0AG//pKtmENFchxaW4+ZV8Cre/BdHx7nN3r4anp7tpGyrgvYcgcyR8+Ae49ik3zeJHIXmQt+ezB/LOh4ptLjE1VR247PF94csLoN9oePl2l8TO+DqMmAoLvuX+bnzJVaQ558DnH4Yob19n8yKXPP2x8NkfQelG97ln3gk+P6z9G6x8Bs67F87/PuR/DWZd6GJNHQrv/NLFPv6aA7+L937r4nx2BgwYDxVb4aIfQ94FUPgv2PkRpAyGiTfB4kdcZdNYBZmjYMCp7nvZ4FW8Hz8Pk25xldiCb7mKsU8/GH2l+579se67WPgfkJAOK56Gbe9BbAos/iPEJsGz10H6CBh4GrTUuUopKtpNF5MIm95060sV1i2Ac77rlqu+HD55AXzRbvraPe573va+276GfRbO/wEsuMd9ZvoIuOX/4LXvw6v3uvirimDDK+CPd8s/5U6X+Nf+DS75ufuufbHwv/fsX4cr/+piLSqAi/8fLPuzK1/+FDRUwus/hCnfhGm/cBXy7GlQuxskCko/ha/+w+0Q1ex26yppoFt39WWuUv/y36GuxFWQsclw6+uQPsyLt9htU+/9Ft79DeTfChkjYMljcPmvYeAEeOlWV/H6ouHy38LpN+//7v9xH+xZ7WK//NeQNsz9hj6ZC9rq3l/zBAya6KZZ8bSL7Yyvu99RYxU8fZVbnj4D4JrZkHN257/7ouVu/Z0yDUZ/Hv5+F/TNdTs5LXWAuM989zduueKSYeWzEGh00+eeD9c+6baBtla3Xf7rfvebVnXbz0U/7vyzjwG7O+7hvPVzePtBVync8c7+Sr47Vj4Hf7vT/bi+u9r9EAD2rodFP4ftS1ylcsciSMuDRQ+4vbj+490GTNB3k3s+XHw/ZJwCvxkFp1wCX5wFsy+BHUvcOIn94LY3Yelj8MHvIedct1dWXQxRfhhxCWQMh+qdbo938BS46lForIRHz4KaXRCTBHcthpL18Ner3TwS0mHsVbBkliv/1nLX0lk112202uqSW1Mt+GPcnrMv2iWg6mJA3PTjrnE/5KZa9+N/5d9cayw6zlVsF9/vkmHwuksfDmWFrmzcNRCf6lpC2xe7YVF+2LPKVaZtLTDkM3Dhf7gKImkgfP1fLpGA65orK4Sh57gEuHMFfO0frmWz+mW3Y/C3b7gKr/CfrvvGF+N+jO3iUlwFAW658i5wldXuT7w9ZoUL7oMNr7llu3uZW87lf4G8C936q9nlKpZbF7rvbNYFrrKMToArHnbr4vUfQXyaSx59h7rE2FTjEuAF90FMgkvOj05xe7e1e6C1yVXAydlQXwotHfaQ4/u6HYkov2sBaKtLCtN+ARNvdutpx1JXKbdXUJmj3HdcthHO+75LvC31bl4NFXDne6716I91Fdar94K2uWVpqXefMf46t61EJ7r101IPn7nHdbM217iEtXuV+76zJx+4vvvmuFbJ+d93v43RV7htdPU8iOnj1s+NL8JHf3WVfLvsM6BomXsdneAq2MxR7rdyznfd/82L3M7ZaTe4RPz8DW7Y6pfctgJu/eR/DYZMgdd+4LbVu5a69fT0dLezUrkN+o1xO1i7V8Nlv3S/v/oymPGsa4VseM0t94U/hI+fdfFKlFtngya4ih/cb79so0vu0YnQXOs+o3qn2z5Pv8XtnLw2023vwWKT4fMPwdq/w+a34UsvuN//xBu7qKAOr6u741riOJy5t7g9LHB7x3nndz1uUYGrmE6b4d6/+BUofNPtwZ5+i/tBFS93lUdMEoy63O1lj/2CqzAeGuc2oumPuCSScQqkZLtKZfEfXYV81l3w9gPwlVfcXnjZJvcD6D/W7e20BdwGlf81uOw3bg+9rdX9+WO6jn3jP+G5GXD5b2DSV1zZogdg6SxXKdd6TfsrHnbDK7fD7ye5GK94GJ65FlIHuxZCQvr+BLt3rfvhpuUe/JnlW1xFE5/qKoQx0/cPa2uFx853SeGzP4L6CreHH5vsKoBBE9yPMDre/YgHnuZ+nK/e69a3+FxraeBpnS9vXalrgTRVBSUCXGX9vXWugmiP46O/ukr7lEtcsioqcJXLqddC1qT907YG3N5iXIqrFF+8BTJGuu/v7O/Axf/tuq/W/A2y8/fvKZdscJXeOd9zZQ2V8NsxLhF8/Y39e7idWft3162YNsxVFJ/MdS2FmETI/6qrXCu2uESVPswldHDdhksec62OAeMOnGdDhatwohNdF19bK8y5yrWu4lJci6G9Er/+rwdOW73TVYgNlS4BZU2C6X9wOzttAZfI/36Xq/wyR7ttPXuSq0DnXOW6Qj/zLbeuN73lWtRTvuHW3eI/wj+8YzBnfgPGX+taZI1Vbps/9XrXGuw3GsZd7RJaU7VLPrMucMmwffttDbhuuZXPwd41LuakQXDPR27b3bzItYDGXwd9vEdPr3/VJZfz7oWC2W5b+fobsNmLc+dH7vdzxtfd+nv8ItfCB9eaCDS6nQbEJagp33B1xLb3YdqDbrz3HnItkIR011I/8w7IOt3F6wvqICpe7lrAUT63rScPglGfdzsUOz9yy9vu+1tcb8IRsMRxpInj0bNcS2HPWlcJ3TSv8/FKC+HxC10F840P3J71L/NcZVhXCp++5irQ3PPcfCbfAYnprs998aNuz37L23DzfNeN0FHldvjjOa6iSxvm9vo7tn5WzXPHR867F0Z8LvRlbapxe3AdtQZcAinfBJf+an930d51bq8+PtXtnUcnHLhxH63dq13XzAX3ufk2VrnEcahWX2OV6xZLzDz8ntbuVTD7UrczcO73YO5X4IyvuR/10WprdYl310pXmV364P5KuzvW/M1VCqOvOPR4qi6x5V3gEne41O51J1JM+Yar2Db+Ewad7rbhrrQ0uArZH+uOKUkUXHifS0xNtQfH21znfit9hwaV1budg/bvfPGfXBfRl//uKvTqXfB/33HJ4ZJf7N82O9rwD5dAp3zjwHJVdwxl0QNw9j2H7o5Whcc/61qqcamudd+e/MEtV3zf/e93rnQJesTFbgersQre/x/XezDswv3Lt2cNDD6j6889EqvmuXU2+Ey383mELHEcSeJoa4WfDXBZPzbFHUv45mK3RwNu4194n+s2aax2zcvWFldp598KT33e7ZH1H+v2DCfctH/vpV1tCTx8mtu7nPoz14/clVXzXBfM1J+6vTJz9Jpq3d65yIHHm4zpzNb3YN6t8IU/7a/8T2CWOI4kcZRtcmcoXPkH16302zEw/mrXvK4rgycvc90Mwz/n9q4++0N31sO7v4XEDLcHf29h53vxwbYvBn+c6345nD1rXVdNV3tWxpjwOol2MLpKHHZW1aGUfur+Z450fYQTb4IVT7m+6Hd+7Y5n3PzygV1LmaNc6yJ9uOvXPlzSAHfgrbv6jwltGYwxx9ZJkjQOJay7rSIyTUQ2iEihiBx0ZZGIxIrIC97wJSKSEzTsPq98g4hc0t15HlPt1zFknOL+f+Zbrlvjzxe5MyPO/vbBxyMS0tzxhy+9AEPPCmt4xhgTCWFLHCLiAx4BLgXGADeISMfd5VuBClUdDjwEPOhNOwaYAYwFpgGPioivm/M8dko/dafpxae6932HwtcWurNN0oa5g9DGGHOSCWdX1WSgUFU3A4jI88B0YG3QONOBn3iv5wF/EBHxyp9X1SZgi4gUevOjG/M8dko/3d/aaJc50p2b39ay/8I4Y4w5iYQzcWQBO4LeFwFndjWOqgZEpApI98oXd5i2/dLpw80TABG5HbgdYMiQIUe2BNmTD7xiu11MwpHNzxhjTgAn7MFxVZ0FzAJ3VtURzWTaz49lSMYYc0II58HxYiD4Cp9sr6zTcUTED6QAZYeYtjvzNMYYE0bhTBzLgBEikisiMbiD3Qs6jLMAuMV7fQ3wproLSxYAM7yzrnKBEcDSbs7TGGNMGIWtq8o7ZnE3sBDwAbNVdY2I3A8UqOoC4AlgjnfwuxyXCPDGm4s76B0A7lLVVoDO5hmuZTDGGHMwu3LcGGNMp7q6ctzuW2GMMSYkljiMMcaExBKHMcaYkFjiMMYYE5KT4uC4iJQA245w8gwgvE9+PzIWV+h6a2wWV2h6a1zQe2M70riGqmpmx8KTInEcDREp6OysgkizuELXW2OzuELTW+OC3hvbsY7LuqqMMcaExBKHMcaYkFjiOLxZkQ6gCxZX6HprbBZXaHprXNB7YzumcdkxDmOMMSGxFocxxpiQWOIwxhgTEkscXRCRaSKyQUQKRWRmhGMZLCJvichaEVkjIt/2yn8iIsUistL7uywCsW0VkVXe5xd4ZWki8k8R2ej979vDMY0MWicrRaRaRL4TqfUlIrNFZK+IrA4q63QdifM7b7v7RERO7+G4fiUi673Pni8iqV55jog0BK27P/VwXF1+dyJyn7e+NojIJT0c1wtBMW0VkZVeeU+ur67qh/BtY6pqfx3+cLds3wTkATHAx8CYCMYzEDjde50EfAqMwT2v/d8jvK62Ahkdyn4JzPRezwQejPB3uRsYGqn1BZwHnA6sPtw6Ai4DXgMEmAIs6eG4pgJ+7/WDQXHlBI8XgfXV6Xfn/Q4+BmKBXO936+upuDoM/w3wnxFYX13VD2HbxqzF0bnJQKGqblbVZuB5YHqkglHVXaq6wntdA6xj/zPYe6PpwFPe66eAqyIYy0XAJlU90jsHHDVVfQf3vJlgXa2j6cDT6iwGUkVkYE/Fpaqvq2rAe7sY95TNHtXF+urKdOB5VW1S1S1AIe7326NxiYgA1wHPheOzD+UQ9UPYtjFLHJ3LAnYEvS+il1TUIpIDTASWeEV3e83N2T3dJeRR4HURWS4it3tl/VV1l/d6N9A/AnG1m8GBP+ZIr692Xa2j3rTtfQ23Z9ouV0Q+EpG3ReTcCMTT2XfXW9bXucAeVd0YVNbj66tD/RC2bcwSx3FERPoALwHfUdVq4I/AMGACsAvXVO5p56jq6cClwF0icl7wQHVt44ic8y3u8cJXAi96Rb1hfR0kkuuoKyLyQ9zTN5/xinYBQ1R1IvA94FkRSe7BkHrldxfkBg7cQenx9dVJ/bDPsd7GLHF0rhgYHPQ+2yuLGBGJxm0Uz6jqywCqukdVW1W1DXicMDXRD0VVi73/e4H5Xgx72pu+3v+9PR2X51Jgharu8WKM+PoK0tU6ivi2JyJfAT4P3OhVOHhdQWXe6+W4Ywmn9FRMh/juesP68gNfBF5oL+vp9dVZ/UAYtzFLHJ1bBowQkVxvr3UGsCBSwXj9p08A61T1t0Hlwf2SXwBWd5w2zHElikhS+2vcgdXVuHV1izfaLcDfezKuIAfsBUZ6fXXQ1TpaAHzZO/NlClAV1N0QdiIyDfg+cKWq1geVZ4qIz3udB4wANvdgXF19dwuAGSISKyK5XlxLeyouz+eA9apa1F7Qk+urq/qBcG5jPXHU/3j8w5158CluT+GHEY7lHFwz8xNgpfd3GTAHWOWVLwAG9nBcebgzWj4G1rSvJyAd+BewEXgDSIvAOksEyoCUoLKIrC9c8toFtOD6k2/tah3hznR5xNvuVgH5PRxXIa7/u307+5M37tXed7wSWAFc0cNxdfndAT/01tcG4NKejMsrfxK4s8O4Pbm+uqofwraN2S1HjDHGhMS6qowxxoTEEocxxpiQWOIwxhgTEkscxhhjQmKJwxhjTEgscRjTi4nIBSLyf5GOw5hgljiMMcaExBKHMceAiNwkIku9Zy88JiI+EakVkYe8ZyT8S0QyvXEniMhi2f/Mi/bnJAwXkTdE5GMRWSEiw7zZ9xGReeKek/GMd6WwMRFjicOYoyQio4HrgbNVdQLQCtyIu3q9QFXHAm8D/+VN8jTwA1U9FXflbnv5M8Ajqnoa8BncVcrg7nb6HdwzFvKAs8O+UMYcgj/SARhzArgImAQs8xoD8bgbyrWx/8Z3fwVeFpEUIFVV3/bKnwJe9O75laWq8wFUtRHAm99S9e6DJO4JcznAe+FfLGM6Z4nDmKMnwFOqet8BhSI/7jDekd7fpynodSv2uzURZl1Vxhy9fwHXiEg/2Pes56G439c13jhfAt5T1SqgIujBPjcDb6t7cluRiFzlzSNWRBJ6dCmM6SbbczHmKKnqWhH5Ee5JiFG4u6feBdQBk71he3HHQcDd4vpPXmLYDHzVK78ZeExE7vfmcW0PLoYx3WZ3xzUmTESkVlX7RDoOY44166oyxhgTEmtxGGOMCYm1OIwxxoTEEocxxpiQWOIwxhgTEkscxhhjQmKJwxhjTEj+P4hddaECfNFRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=  74.59687539339066\n"
     ]
    }
   ],
   "source": [
    "print('Time= ', (toc_fit - tic)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Noorani_env",
   "language": "python",
   "name": "noorani_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
