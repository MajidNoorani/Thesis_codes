{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries.\n",
    "import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras\n",
    "from keras import regularizers, optimizers\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.initializers import glorot_normal\n",
    "import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "from mir_eval import separation \n",
    "from pystoi.stoi import stoi \n",
    "import h5py\n",
    "from keras.callbacks import LearningRateScheduler, Callback, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "import time\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "# from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(wave,angle):\n",
    "    recon1 = wave*np.cos(angle)+wave*np.sin(angle)*1j\n",
    "#     recon = np.sqrt(np.power(10, wave))\n",
    "#     recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=512, win_length=2048, window='hann')\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 10000)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TSP/Organized/concatenated/Second_set/Train2_TSP_mixed_FFT'  + data_series + '.hdf5','r')\n",
    "mixed = h5f['Train2_TSP_mixed_FFT' + data_series][:,0:10000]\n",
    "print(mixed.shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 10000)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TSP/Organized/concatenated/Second_set/Train2_TSP_mixed_phase'  + data_series + '.hdf5','r')\n",
    "mixed_phase = h5f['Train2_TSP_mixed_phase' + data_series][:,0:10000]\n",
    "print(mixed_phase.shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2050, 10000)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TSP/Organized/concatenated/Second_set/Train2_TSP_clean_FFTs'  + data_series + '.hdf5','r')\n",
    "clean = h5f['Train2_TSP_clean_FFTs' + data_series][:,0:10000]\n",
    "print(clean.shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2050, 10000)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TSP/Organized/concatenated/Second_set/Train2_TSP_clean_phases'  + data_series + '.hdf5','r')\n",
    "clean_phase = h5f['Train2_TSP_clean_phases' + data_series][:,0:10000]\n",
    "print(clean_phase.shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2050)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('TSP/Predicted/predicted_TSP_FFT'  + data_series + '.hdf5','r')\n",
    "predicted = h5f['predicted_TSP_FFT' + data_series][0:10000]\n",
    "print(predicted.shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = preprocessing.normalize(mixed, norm='l2', axis=0, copy=True)\n",
    "c_normalized = preprocessing.normalize(clean, norm='l2', axis=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_samples = 1025\n",
    "clean_recon1 = reconstruct(clean[0:fft_samples,:].T, clean_phase[0:fft_samples,:].T)\n",
    "clean_recon2 = reconstruct(clean[fft_samples:,:].T, clean_phase[fft_samples:,:].T)\n",
    "mixed_recon = reconstruct(mixed.T, mixed_phase.T)\n",
    "predicted_recon1 = reconstruct(predicted[:,0:fft_samples], mixed_phase.T)\n",
    "predicted_recon2 = reconstruct(predicted[:,fft_samples:], mixed_phase.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5119488,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 48000\n",
    "sd.play(predicted_recon2[0:519488], sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(clean_recon2[0:519488], sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.zeros(train_input.shape[1])\n",
    "for i in range(train_input.shape[1]):\n",
    "    norms[i] = np.linalg.norm(train_input[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('TSP/Predicted/Valid_predicted_TSP_FFT' + data_series + '.hdf5', 'w')\n",
    "hf.create_dataset('Valid_predicted_TSP_FFT' + data_series, data=prediction)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
